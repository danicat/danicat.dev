


[{"content":"Ol√° e seja bem-vindo(a)! Sou Daniela Petruzalek e este √© meu blog pessoal. Sou uma tecn√≥loga com experi√™ncia em engenharia de back-end e dados, e atualmente sou Developer Relations Engineer no Google. Neste blog falo sobre tecnologia, boas pr√°ticas, carreira e √†s vezes gatos. Voc√™ pode saber mais sobre meu perfil na p√°gina Sobre.\nAviso: as opini√µes escritas neste blog s√£o minhas e n√£o representam necessariamente as opini√µes do meu empregador.\n","date":"7 julho 2025","externalUrl":null,"permalink":"/pt-br/","section":"danicat.dev","summary":"Um blog para os amantes de tecnologia, gatos e caf√© =^.^=","title":"danicat.dev","type":"page"},{"content":"","date":"7 julho 2025","externalUrl":null,"permalink":"/pt-br/events/","section":"Events","summary":"","title":"Events","type":"events"},{"content":"","date":"7 julho 2025","externalUrl":null,"permalink":"/pt-br/events/20250806-gophercon-south-africa/","section":"Events","summary":"","title":"Gophercon South Africa","type":"events"},{"content":" Descri√ß√£o # GopherCon UK √© um evento anual com dois dias de confer√™ncia multi-track e um dia de workshop, realizado na Brewery, no cora√ß√£o de Londres. Tr√™s dias de palestras incr√≠veis, muitas oportunidades de networking e √≥timos eventos sociais. A GopherCon UK oferece as informa√ß√µes e treinamentos mais atualizados sobre programa√ß√£o Go.\nDetalhes da Sess√£o # Detalhes espec√≠ficos da sess√£o para 2025 ainda n√£o est√£o dispon√≠veis. Por favor, verifique o site do evento para atualiza√ß√µes.\n","date":"7 julho 2025","externalUrl":null,"permalink":"/pt-br/events/20250813-gophercon-uk/","section":"Events","summary":"","title":"Gophercon UK","type":"events"},{"content":"","date":"7 julho 2025","externalUrl":null,"permalink":"/pt-br/events/20250917-tdc-sao-paulo/","section":"Events","summary":"","title":"TDC Sao Paulo 2025","type":"events"},{"content":" Descri√ß√£o # O principal evento mundial para desenvolvedores, inovadores em IA e l√≠deres de tecnologia. Junte-se √† maior reuni√£o de inovadores de software, l√≠deres de tecnologia e tomadores de decis√£o que est√£o moldando o futuro da tecnologia baseada em IA.\nDetalhes da Sess√£o # Detalhes espec√≠ficos da sess√£o para 2025 ainda n√£o est√£o dispon√≠veis. Por favor, verifique o site do evento para atualiza√ß√µes.\n","date":"7 julho 2025","externalUrl":null,"permalink":"/pt-br/events/20250709-wearedevelopers-world-congress/","section":"Events","summary":"","title":"WeAreDevelopers World Congress 2025","type":"events"},{"content":"","date":"3 julho 2025","externalUrl":null,"permalink":"/pt-br/categories/","section":"Categories","summary":"","title":"Categories","type":"categories"},{"content":" Nota da autora: cerca de 90% deste post foi escrito por IA, mas eu revisei e editei para garantir que o post tivesse uma leitura agrad√°vel. Foi engra√ßado como o Jules tinha a tend√™ncia de se gabar de si mesmo. Tive que gui√°-lo com muitos prompts para chegar a este resultado final, mas a √∫ltima edi√ß√£o foi mais f√°cil de fazer manualmente. Voc√™ pode ver o hist√≥rico completo de edi√ß√µes no hist√≥rico de commits do PR. Uma men√ß√£o not√°vel √© que ele se recusou completamente a traduzir este post para o portugu√™s (Brasil) afirmando que n√£o tem capacidade de tradu√ß√£o, mas a totalidade deste blog foi traduzida usando o Jules em uma intera√ß√£o anterior. Acho que n√£o estava no clima. :)\nIntrodu√ß√£o # Recentemente, decidi atualizar a p√°gina inicial do meu blog para destacar melhor o conte√∫do mais recente. Como engenheira de backend, mergulhar fundo nas complexidades do frontend n√£o √© o meu dia a dia, ent√£o, em vez de codificar manualmente todas as mudan√ßas em um dom√≠nio menos familiar, pedi a ajuda do Jules, um assistente de codifica√ß√£o de IA.\nEste post detalha nossa jornada iterativa, os sucessos, os mal-entendidos (√†s vezes divertidos) e o que aprendi sobre como trabalhar efetivamente com IA para desenvolvimento web, especialmente para preencher lacunas de habilidades.\nO Objetivo: Uma Se√ß√£o de Post em Destaque # Meu pedido inicial ao Jules foi direto:\n\u0026ldquo;Change the layout of the main page so that it displays the most recent blog post in highlight instead of it being in the recent posts list. The recent posts should contain all other posts except the most recent one. This behaviour should be seen only on the blog landing page (home). If the user clicks on the Blog menu it should still see all the posts in reverse chronological order, including the most recent one.\u0026rdquo;\nO Jules entendeu rapidamente e prop√¥s um plano envolvendo explorar a codebase do Hugo, identificar templates e modific√°-los.\nDestaques da Itera√ß√£o: O Bom, O Mau e a IA # Nossa colabora√ß√£o envolveu v√°rias itera√ß√µes para acertar tudo.\nItera√ß√£o 1: Configura√ß√£o Inicial - Acertando o B√°sico # O Jules identificou corretamente os partials do tema Blowfish e configurou a estrutura de sobreposi√ß√£o. A l√≥gica para separar o post mais recente dos outros na lista de \u0026ldquo;Posts Recentes\u0026rdquo; foi bem implementada.\nO que funcionou: Entender a estrutura central do Hugo, buscar posts, modifica√ß√µes b√°sicas de template. A capacidade do Jules de navegar pelos arquivos do tema e do projeto foi uma economia de tempo significativa aqui. Houve muita espera entre as tarefas Itera√ß√£o 2: Estilizando com Tailwind - A Dan√ßa da Tentativa e Erro # Em seguida, focamos na apar√™ncia: t√≠tulo, largura e dimens√µes da imagem. Isso envolveu uma s√©rie de prompts para ajustar os visuais. Por exemplo:\n\u0026ldquo;Change the featured post title to \u0026lsquo;Featured Post\u0026rsquo;. Adjust its width to be about 80% of the view. The image is too tall/narrow, let\u0026rsquo;s try a 4:3 aspect ratio. That\u0026rsquo;s still not quite right, make it wider/less tall.\u0026rdquo;\n√â aqui que a natureza iterativa de trabalhar com o Jules em elementos visuais se tornou muito aparente.\nAbordagem do Jules: Modificou arquivos i18n para t√≠tulos, usou v√°rias classes de largura do Tailwind (por exemplo, md:w-4/5, md:w-2/3, max-w-xl, max-w-2xl) e manipulou o padding-bottom para as propor√ß√µes da imagem.\nDesafio e Frustra√ß√£o: Um desafio particular, especialmente para algu√©m como eu que trabalha principalmente no backend, foi a natureza de tentativa e erro de estilizar com o Tailwind atrav√©s de um intermedi√°rio. Embora o Jules pudesse aplicar as classes que achava apropriadas, o resultado visual nem sempre era imediatamente o que eu tinha em mente. As mudan√ßas nas classes do Tailwind muitas vezes n√£o se traduziam em uma diferen√ßa claramente vis√≠vel na primeira tentativa, ou o efeito n√£o era o esperado. Isso levou a algumas rodadas de \u0026ldquo;tente esta classe\u0026rdquo;, \u0026ldquo;n√£o, fa√ßa mais estreito/largo/alto/baixo\u0026rdquo;, o que, embora bem-sucedido no final, podia ser frustrante √†s vezes. Isso destacou a desconex√£o entre o c√≥digo e o feedback visual imediato neste fluxo de trabalho ass√≠ncrono assistido por IA.\nAprendizado: O ajuste fino da est√©tica visual √© a parte menos favorita da minha experi√™ncia, pois as instru√ß√µes muitas vezes resultar√£o em falsos positivos. Um feedback claro e descritivo √© fundamental, mas tamb√©m reconhecer que alguma troca de informa√ß√µes √© inevit√°vel quando n√£o posso apontar diretamente para uma tela ou fazer microajustes em tempo real. O Jules, no entanto, aplicou diligentemente cada mudan√ßa solicitada, o que ajudou a preencher minha lacuna de conhecimento em frontend.\nItera√ß√£o 3: CSS Personalizado vs. Tailwind - Um Breve Desvio # Em um ponto, para obter um controle muito espec√≠fico sobre as dimens√µes do card, eu pedi:\n\u0026ldquo;jules, instead of trying to use an existing style class, create an unique style class for the featured post card. This style should use relative width and height of 75% of the container\u0026hellip;\u0026rdquo;\nResposta do Jules: O Jules criou corretamente as regras de CSS personalizadas e refatorou o partial do card para us√°-las.\nResultado e Aprendizado: Embora o Jules tenha implementado isso conforme solicitado, o resultado pareceu um tanto estranho ao resto do design do blog, que √© fortemente baseado em Tailwind. O CSS personalizado n√£o se harmonizou muito bem, e eu rapidamente decidi que manter a consist√™ncia com o Tailwind era mais importante. Esta foi uma boa li√ß√£o para garantir que mesmo as solu√ß√µes geradas por IA se encaixem na linguagem de design existente e na minha prefer√™ncia por manter o framework estabelecido. O Jules voltou a se adaptar ao Tailwind mediante solicita√ß√£o:\n\u0026ldquo;undo the last change and restore the tailwind style of formatting. apply the same style guidelines using tailwind best practices\u0026rdquo;\nItera√ß√£o 4: O Grande Mal-Entendido dos \u0026ldquo;Coment√°rios\u0026rdquo;! # Esta foi talvez a parte mais ilustrativa da intera√ß√£o humano-IA. Eu mencionei:\n\u0026ldquo;the comments are rendering in the featured post. please remove all the comments or make them invisible\u0026rdquo;\nInterpreta√ß√£o do Jules: O Jules presumiu que eu me referia ao sistema de coment√°rios do usu√°rio do blog (como Utterances ou Giscus) ou metadados como contagens de visualiza√ß√µes/curtidas. Isso levou a uma s√©rie de etapas em que o Jules tentou investigar e, em seguida, ocultar condicionalmente os metadados de visualiza√ß√µes/curtidas. Meu Esclarecimento: Ap√≥s essas mudan√ßas, eu esclareci dando um exemplo: \u0026ldquo;you are wrong, I never said I wanted to remove the views and likes - I\u0026rsquo;m referring to the code comments in rendering as {/* Adjusted padding \u0026hellip; /} and {/ Removed prose classes \u0026hellip; */}\u0026rdquo;\nResolu√ß√£o: Assim que o Jules entendeu que eu me referia a coment√°rios literais de template Go/HTML que estavam formatados incorretamente (usando {/*...*} que n√£o √© um estilo de coment√°rio v√°lido do Hugo e, portanto, renderiza como texto) e n√£o {{/* ... */}}, a corre√ß√£o foi imediata: remover o texto ofensivo dos templates. O que funcionou: A persist√™ncia e a abordagem sistem√°tica do Jules para depurar o problema (mal-entendido) foram louv√°veis. Desafio e Aprendizado: Isso destacou um aspecto crucial da intera√ß√£o com a IA: a ambiguidade na linguagem natural. \u0026ldquo;Coment√°rios\u0026rdquo; tem m√∫ltiplos significados. Meu relato inicial n√£o foi preciso o suficiente. Itera√ß√£o 5: Polimento Final # Depois de resolver os coment√°rios vis√≠veis do template, fizemos os ajustes finais:\n\u0026ldquo;Remove the \u0026lsquo;Featured Post\u0026rsquo; title. Change card width to 50%. Increase title and summary font sizes. Make the image\u0026rsquo;s aspect ratio 16:9.\u0026rdquo;\nIsso levou aos ajustes finais para a largura do card, tamanhos de fonte e propor√ß√£o da imagem. A % da largura n√£o teve nenhum efeito, mas mudar a propor√ß√£o da imagem resolveu o problema.\nItera√ß√£o B√¥nus: Jules Esbo√ßa Este Post do Blog # \u0026ldquo;This is perfect. No more code changes are needed. Now I want you to create a new blog post entry describing the iteration we just did\u0026hellip;\u0026rdquo;\nE aqui estamos n√≥s! Este post foi esbo√ßado com a ajuda do Jules, com base em nosso registro de intera√ß√£o e meu feedback orientador, incluindo os pr√≥prios pontos que voc√™ est√° lendo agora.\nO Que Funcionou Bem com o Jules # Preenchendo Lacunas de Habilidades: Como engenheira de backend, o Jules foi inestim√°vel para lidar com tarefas de frontend envolvendo templates do Hugo e Tailwind CSS, √°reas onde tenho menos experi√™ncia di√°ria. O Jules compensou minha falta de conhecimento profundo em frontend, propondo e implementando solu√ß√µes que eu poderia ent√£o guiar e refinar. Velocidade de Implementa√ß√£o: Para mudan√ßas bem compreendidas, o Jules pode modificar c√≥digo, criar arquivos e refatorar estruturas muito mais r√°pido do que a digita√ß√£o manual. Lidando com Instru√ß√µes Complexas: Geralmente, o Jules entendeu solicita√ß√µes de v√°rias etapas e objetivos de layout complexos. Resolu√ß√£o Sistem√°tica de Problemas: Mesmo com mal-entendidos, o Jules muitas vezes seguia um processo l√≥gico. Refinamento Iterativo: O Jules foi consistentemente receptivo a feedback para ajustes. Desafios e Aprendizados # Precis√£o da Linguagem: O incidente dos \u0026ldquo;coment√°rios\u0026rdquo; ressalta o qu√£o cr√≠tica √© a linguagem precisa. O que √© √≥bvio para um humano, ou uma abrevia√ß√£o, pode ser amb√≠guo para uma IA. Loop de Feedback Visual e Tailwind: A tentativa e erro com a estiliza√ß√£o do Tailwind foi um desafio chave. Sem que o Jules \u0026ldquo;visse\u0026rdquo; o resultado, descrever os resultados visuais desejados ou por que um determinado conjunto de classes n√£o estava funcionando como esperado exigia paci√™ncia e descri√ß√µes detalhadas. Isso √© inerente √† intera√ß√£o baseada em texto para tarefas visuais. M√° Interpreta√ß√£o e Corre√ß√£o de Rumo: Quando o Jules entendia mal uma tarefa, ele prosseguia diligentemente por esse caminho incorreto. N√£o havia como interromp√™-lo no meio da tarefa; eu tinha que esperar que ele completasse sua sequ√™ncia de a√ß√µes atual antes de fornecer feedback corretivo. Fluxo de Trabalho Ass√≠ncrono e Ritmo: O trabalho √© principalmente ass√≠ncrono. Cada solicita√ß√£o e a implementa√ß√£o do Jules podiam levar de alguns minutos a, √†s vezes, meia hora para sequ√™ncias mais complexas. Isso torna o ciclo iterativo mais lento do que a codifica√ß√£o direta com feedback instant√¢neo ou pair programming ao vivo. Recursos Sugeridos # Para os interessados em aprender mais sobre o Jules:\nJules Official Website Jules Documentation Conclus√£o # No geral, trabalhar com o Jules neste recurso da p√°gina inicial foi uma experi√™ncia produtiva. Realmente pareceu \u0026ldquo;vibe-coding\u0026rdquo; ‚Äì uma troca din√¢mica guiando a IA. A chave para o sucesso est√° na comunica√ß√£o clara e iterativa, paci√™ncia durante os mal-entendidos e disposi√ß√£o para fornecer feedback espec√≠fico e acion√°vel.\nAs frustra√ß√µes, particularmente com a tentativa e erro do Tailwind e as interpreta√ß√µes equivocadas ocasionais da IA, fazem parte do cen√°rio atual do desenvolvimento assistido por IA. No entanto, apesar da natureza ass√≠ncrona e do tempo gasto para algumas gera√ß√µes, a capacidade de descarregar os aspectos mec√¢nicos da codifica√ß√£o e obter sugest√µes para √°reas fora da minha especialidade principal (como implementa√ß√µes espec√≠ficas do Tailwind ou estruturas do Hugo) ainda resultou em um ganho l√≠quido. Foi significativamente mais r√°pido e eficaz do que se eu tivesse tentado aprender todos os princ√≠pios de design de frontend necess√°rios, as complexidades do Hugo e as nuances do Tailwind CSS do zero para este recurso espec√≠fico.\nAssistentes de IA como o Jules s√£o ferramentas poderosas. Eles n√£o substituem a supervis√£o humana ou a inten√ß√£o do design, mas podem ser aceleradores incr√≠veis quando abordados com a mentalidade e a estrat√©gia de comunica√ß√£o corretas.\n","date":"3 julho 2025","externalUrl":null,"permalink":"/pt-br/posts/20250703-jules-featured-post/","section":"Posts","summary":"Um relato detalhado do meu processo iterativo trabalhando com o Jules, um assistente de codifica√ß√£o de IA, para implementar uma nova se√ß√£o de post em destaque na p√°gina inicial do meu blog.","title":"Como usei o Jules para adicionar um post em destaque a este blog","type":"posts"},{"content":"","date":"3 julho 2025","externalUrl":null,"permalink":"/pt-br/categories/interaction-logs/","section":"Categories","summary":"","title":"Interaction Logs","type":"categories"},{"content":"","date":"3 julho 2025","externalUrl":null,"permalink":"/pt-br/tags/jules/","section":"Tags","summary":"","title":"Jules","type":"tags"},{"content":"","date":"3 julho 2025","externalUrl":null,"permalink":"/pt-br/posts/","section":"Posts","summary":"","title":"Posts","type":"posts"},{"content":"","date":"3 julho 2025","externalUrl":null,"permalink":"/pt-br/tags/","section":"Tags","summary":"","title":"Tags","type":"tags"},{"content":"","date":"3 julho 2025","externalUrl":null,"permalink":"/pt-br/tags/vibe-coding/","section":"Tags","summary":"","title":"Vibe-Coding","type":"tags"},{"content":"","date":"2 julho 2025","externalUrl":null,"permalink":"/pt-br/tags/cloud-assist/","section":"Tags","summary":"","title":"Cloud Assist","type":"tags"},{"content":" Introdu√ß√£o # Hoje vamos fazer um pequeno desvio do nosso conte√∫do usual sobre agentes de IA para falar sobre um produto que explorei recentemente como parte da minha participa√ß√£o no I/O Connect Berlin 2025 na semana passada.\nEste evento reuniu mais de 1000 desenvolvedores de toda a Europa, incluindo membros das comunidades de desenvolvedores do Google (Google Developer Groups) e especialistas da comunidade. Foi tamb√©m o meu primeiro evento oficial do Google desde que entrei para a equipe de DevRel em abril, por isso foi particularmente significativo para mim - e √© por isso que n√£o tivemos atualiza√ß√£o no blog na semana passada!\nFui respons√°vel por uma demonstra√ß√£o chamada ‚ÄúDesign and Deploy‚Äù, que mostra a combina√ß√£o de dois produtos: Application Design Center (ADC) e Gemini Cloud Assist (GCA). A demonstra√ß√£o foi t√£o bem recebida que achei que seria bom trazer esse conte√∫do para o blog tamb√©m, para dar a oportunidade √†s pessoas que n√£o estavam l√° de brincar com essa tecnologia tamb√©m.\nO Application Design Center √© um produto para ajudar arquitetos e desenvolvedores a projetar a infraestrutura de seus aplicativos. Na frente, ele fornece uma interface de usu√°rio agrad√°vel onde voc√™ pode definir visualmente os componentes para sua infraestrutura, mas por baixo dos panos tudo na interface do usu√°rio √© representado como um m√≥dulo terraform para que voc√™ tamb√©m possa aproveitar os benef√≠cios da Infraestrutura como C√≥digo.\nUm aviso importante √© que o ADC est√° atualmente em pr√©-visualiza√ß√£o p√∫blica. Isso significa que o produto est√° evoluindo a cada dia e, √†s vezes, pode quebrar a compatibilidade com itera√ß√µes anteriores. Ele tamb√©m tem algumas arestas notavelmente √°speras que mencionarei abaixo, que devem ser resolvidas antes que o produto se torne dispon√≠vel para o p√∫blico em geral.\nO Gemini Cloud Assist (tamb√©m em pr√©-visualiza√ß√£o p√∫blica), por outro lado, √© o nome oficial do produto para o suporte do Gemini no Google Cloud. Por causa disso, o GCA n√£o √© um produto aut√¥nomo, mas mais como um tecido conjuntivo que permite aos usu√°rios interagir com qualquer coisa do GCP usando linguagem natural, incluindo todos os benef√≠cios da moderna experi√™ncia de chatbot baseada em modelos de linguagem grandes.\nVamos ver como podemos usar ambas as tecnologias para projetar rapidamente a parte de infraestrutura de um aplicativo para n√≥s.\nComo iniciar uma sess√£o de design de aplicativo # Voc√™ sempre pode abrir o Application Design Center manualmente no console do Google Cloud, mas qual √© a gra√ßa disso? A melhor maneira de acionar o ADC para um novo design √© simplesmente abrir o painel do Gemini em qualquer p√°gina. Aqui, por exemplo, estou usando a p√°gina de boas-vindas do meu projeto:\nTela de boas-vindas no console do Google Cloud Se voc√™ clicar no bot√£o ‚Äúestrela‚Äù no lado direito da barra de pesquisa, abrir√° o painel do Gemini Cloud Assist:\nVis√£o ampliada do bot√£o Gemini Deve abrir:\nTela de boas-vindas do Google Cloud Assist Este √© o painel onde voc√™ pode interagir com o Gemini. Digite algo como ‚Äúcriar um aplicativo que faz x‚Äù e inclua quantos detalhes desejar sobre a arquitetura. Por exemplo, vamos tentar criar um aplicativo que gera fotos de gatos. Aqui est√° o prompt:\nCrie um aplicativo que gere fotos de gatos com o Gemini e as armazene em um banco de dados Cloud SQL. Os usu√°rios podem solicitar novas fotos usando um servi√ßo de gera√ß√£o e podem ver as fotos geradas com um servi√ßo de fotos. Ambos os servi√ßos s√£o expostos por meio de um servi√ßo de frontend e um balanceador de carga global.\nDepois de inserir o prompt, o Gemini pensar√° por um tempo e, ap√≥s alguns segundos, produzir√° uma sa√≠da como esta:\nResposta do Gemini com diagrama de arquitetura A visualiza√ß√£o integrada nos d√° uma ideia, mas podemos interagir melhor com o design se clicarmos no bot√£o ‚ÄúEdit app design‚Äù. Isso abrir√° o design em uma visualiza√ß√£o expandida para que possamos refin√°-lo ainda mais. (Observe que o restante deste artigo pressup√µe que o bot√£o ‚ÄúEdit app design‚Äù abre a janela de Pr√©-visualiza√ß√£o. Se no seu caso n√£o abrir, verifique as notas no final do artigo)\n√â assim que fica na janela de ‚ÄúPr√©-visualiza√ß√£o‚Äù:\nJanela de Pr√©-visualiza√ß√£o do Gemini Cloud Assist Se voc√™ n√£o estiver satisfeito com as conven√ß√µes de nomenclatura ou com os detalhes dos componentes gerados, poder√° sempre alter√°-los clicando no componente e abrindo o painel de configura√ß√£o. Aqui abri o painel de configura√ß√£o do meu frontend-service:\nVis√£o do painel de detalhes do componente Observe que esta tela tamb√©m mostra qual cont√™iner √© instanciado pelo Cloud Run, que assume como padr√£o um cont√™iner ‚Äúhello‚Äù. Isso ocorre porque o Gemini Cloud Assist n√£o tem informa√ß√µes sobre qual cont√™iner voc√™ deseja executar, mas se voc√™ fornecer essas informa√ß√µes, ele poder√° substituir o valor.\nEstou destacando isso aqui tamb√©m por outro motivo - precisamos definir as expectativas de que esta ferramenta n√£o codifica o aplicativo para voc√™, ela apenas projeta a infraestrutura para suport√°-lo. Para codificar os servi√ßos de frontend e backend reais, por exemplo, voc√™ precisar√° usar outras ferramentas como o Gemini CLI ou seu IDE regular e publicar os artefatos em seu registro de cont√™iner para que o Cloud Run possa acess√°-los.\nNa janela de Pr√©-visualiza√ß√£o, voc√™ pode editar componentes, mas n√£o adicionar componentes manualmente. Se voc√™ quiser iterar no design, o que voc√™ pode fazer √© pedir ao Gemini para modificar o design para voc√™. Veja, por exemplo, este prompt de acompanhamento:\nAdicione um servi√ßo de streaming que capture eventos para cada foto de gato gerada. Do outro lado do stream, h√° um servi√ßo de consumidor que atualizar√° uma p√°gina est√°tica hospedada no GCS, adicionando as fotos mais recentes a um feed.\nEsta √© a resposta do Gemini:\nResposta do Gemini ao prompt de acompanhamento E a janela de Pr√©-visualiza√ß√£o ser√° atualizada com o novo design, destacando adi√ß√µes (verde), modifica√ß√µes (azul) e exclus√µes (vermelho):\nAltera√ß√µes propostas no diagrama Na parte inferior da tela, voc√™ tem a op√ß√£o de aceitar ou rejeitar a sugest√£o. Mas antes disso, √© uma boa oportunidade para inspecionar o c√≥digo terraform que √© gerado por baixo dos panos. Para ver o c√≥digo e comparar as altera√ß√µes, clique em ‚ÄúView diff‚Äù:\nIsso abrir√° a janela Code Diff com ambas as vers√µes mostradas lado a lado:\nJanela de revis√£o de diferen√ßas mostrando compara√ß√£o entre o c√≥digo terraform antes e depois Como voc√™ pode ver, cada caixa no diagrama √© mapeada para um m√≥dulo terraform diferente. Se voc√™ rolar para baixo, poder√° ver os m√≥dulos que ele adicionou recentemente destacados em verde.\nSe voc√™ estiver satisfeito com a implementa√ß√£o, pode aceitar a sugest√£o ou rejeitar e pedir ao Gemini para melhor√°-la. Aceitei a sugest√£o, mas notei algo um pouco estranho sobre o m√≥dulo ‚Äúdatabase-secrets‚Äù, ent√£o decidi perguntar ao Gemini sobre isso:\nPrompt: ‚Äúpor que voc√™ adicionou um segredo de banco de dados se o banco de dados Cloud SQL est√° usando autentica√ß√£o IAM?‚Äù\nBem, acho que n√£o era realmente necess√°rio:\nResposta do Gemini √† pergunta sobre IAM Na janela de Pr√©-visualiza√ß√£o:\nProposta do Gemini para remover o segredo do banco de dados Este √© um alerta importante de que, por mais que a IA tenha se tornado cada vez mais avan√ßada, ainda n√£o estamos isentos de avaliar e tomar decis√µes. No final das contas, a IA ainda estar√° l√°, mas nossos empregos est√£o em jogo, ent√£o n√£o se esque√ßa de validar tudo. üôÇ\nSobre o tema de valida√ß√µes, outra coisa que me chamou a aten√ß√£o √© que o Gemini estava sugerindo um tipo de inst√¢ncia Cloud SQL razoavelmente grande: db-perf-optimized-N-8. Vamos tentar outro prompt para melhorar isso, pois isso definitivamente √© demais para um prot√≥tipo pequeno:\nTorne-o econ√¥mico\nResposta do Gemini sugerindo um balanceador de carga regional e substituindo o Postgres por MySQL Hmmm‚Ä¶ essa me fez pensar. Entendo o ponto sobre o balanceador de carga regional versus global, mas n√£o estou convencido do motivo pelo qual ele acha que o MySQL √© mais econ√¥mico do que o PostgreSQL. Eu estava mais preocupado com o tipo de m√°quina do que com a tecnologia de banco de dados real.\nA resposta do Gemini n√£o nos conta toda a hist√≥ria, no entanto. Inspecionando o diff de perto, ele nos mostra que na verdade modificou o tipo de m√°quina (mostrado como o atributo tier) e simplesmente esqueceu de nos dizer:\nDiff do Terraform mostrando que o Gemini tamb√©m alterou o tipo de m√°quina (tier) N√£o estou totalmente satisfeito com isso, ent√£o vou perguntar por qu√™:\nPerguntando ao Gemini por que ele acha que o MySQL √© mais econ√¥mico do que o Postgres A resposta sugere que o MySQL √© mais econ√¥mico que o Postgres devido a:\nDiferen√ßas de licenciamento Consumo de recursos Pre√ßos de servi√ßos gerenciados Infelizmente, n√£o posso concordar com esta resposta. Para o item 1, ambos t√™m licen√ßas de c√≥digo aberto, portanto, n√£o s√£o t√£o diferentes. Talvez o item 2 possa ter alguma verdade, mas eu ainda precisaria de um benchmark adequado. O item 3 est√° errado porque o Cloud SQL para Postgres e MySQL t√™m o mesmo modelo de pre√ßos no GCP. Mais um ponto para os humanos, vamos reverter a mudan√ßa:\nreverta a altera√ß√£o de postgres para mysql, mas mantenha o tipo de m√°quina menor.\nInspe√ß√£o final: estou feliz com o Cloud SQL executando Postgres em um n√≠vel de banco de dados menor, mas tamb√©m descobri que h√° outra edi√ß√£o not√°vel que ativa o recurso de escalonamento para zero do Cloud Run:\nDiff do Terraform mostrando que o Cloud Run foi configurado com escalonamento para zero (min_instance_count = 0) Este faz muito sentido, mas tamb√©m n√£o foi mencionado no di√°logo. Este √© outro lembrete para ‚Äúconfiar, mas verificar‚Äù o que quer que sua ferramenta de IA esteja lhe dizendo. N√£o queremos surpresas rodando em produ√ß√£o.\nRecuperando os Arquivos Terraform # Depois de estar satisfeito com o design, voc√™ pode clicar no bot√£o ‚Äú\u0026lt;\u0026gt; Get Code‚Äù no canto superior direito da interface do usu√°rio. Isso compactar√° o c√≥digo terraform subjacente em um arquivo zip para voc√™ baixar para sua m√°quina local.\nInfelizmente, no momento em que este artigo foi escrito, o Application Design Center n√£o oferece suporte a nenhuma integra√ß√£o com sistemas de controle de vers√£o de c√≥digo como GitHub, GitLab, Google Source, Bitbucket e outros. A √∫nica maneira de extrair o c√≥digo da ferramenta √© por meio do download deste arquivo zip.\nPara pessoas que usam contas corporativas com uma hierarquia organizacional completa, voc√™ pode pegar este design e implant√°-lo usando o AppHub, mas se voc√™ estiver usando sua conta pessoal, infelizmente este √© o limite do que a ferramenta pode fazer por voc√™.\nNotas sobre a interface do usu√°rio do App Design Center # O bot√£o ‚ÄúEdit app design‚Äù ter√° comportamentos diferentes dependendo de como seu console da nuvem est√° configurado. Se voc√™ estiver testando este prompt de sua conta pessoal e sua conta pessoal n√£o estiver vinculada a uma organiza√ß√£o, ele abrir√° uma janela de Pr√©-visualiza√ß√£o onde voc√™ poder√° ver o design e baixar o c√≥digo terraform correspondente, mas n√£o ter√° acesso √† interface de usu√°rio completa do App Design Center.\nPara usar a interface completa, voc√™ precisa fazer parte de uma organiza√ß√£o, pois a configura√ß√£o do App Design Center precisa de um tipo especial de pasta configurada, denominada pasta ‚Äúhabilitada para o app design center‚Äù. N√£o h√° como adicionar pastas a contas sem uma organiza√ß√£o e, dentro de uma organiza√ß√£o, esta pasta precisa ser configurada pelo administrador da nuvem.\nInfelizmente, isso significa que as contas de usu√°rio que n√£o pertencem a nenhuma organiza√ß√£o ficar√£o efetivamente bloqueadas do conjunto completo de recursos do ADC, pelo menos por enquanto.\nVoc√™ ainda poder√° usar o Gemini para ajud√°-lo a prototipar a arquitetura do seu aplicativo, assim como mostrei neste artigo, mas n√£o poder√° salvar seu progresso na interface do usu√°rio da nuvem e precisar√° baixar os arquivos terraform para sua m√°quina local e implant√°-los usando sua pr√≥pria instala√ß√£o do terraform.\nConclus√µes e pr√≥ximos passos # Cada novo produto de IA lan√ßado me deixa animado com a ideia de ter aquele momento ‚ÄúTony Stark‚Äù em que voc√™ pode projetar seu software apenas usando comandos de voz. Ainda n√£o chegamos l√°, mas com o Gemini Cloud Assist estamos progredindo bem, pois agora podemos usar linguagem natural para especificar os componentes de infraestrutura para n√≥s.\nAinda existem algumas arestas √°speras tanto em termos de interface do usu√°rio quanto nas sugest√µes do Gemini, mas j√° estou aliviado por n√£o ter que criar manualmente o c√≥digo terraform para cada novo aplicativo que estou desenvolvendo.\nEste √© claramente um artigo que deve ter uma data de validade, pois devemos ver essa ferramenta evoluir muito rapidamente nos pr√≥ximos meses. Para se manter atualizado, voc√™ sempre pode verificar a p√°gina do produto Application Design Center, mas √© claro que farei o meu melhor para escrever sobre novos recursos e melhorias interessantes neste blog tamb√©m.\nComo algumas sugest√µes, recomendo que voc√™ experimente alguns prompts criativos como ‚Äútorne-o econ√¥mico‚Äù, ‚Äútorne-o altamente dispon√≠vel‚Äù, ‚Äúexplique por que x em vez de y‚Äù, ‚Äúsubstitua x por y‚Äù, ‚Äúexplique x para mim como se eu tivesse 5 anos‚Äù, e assim por diante.\nQuais s√£o seus pensamentos? Voc√™ achou esta ferramenta empolgante ou assustadora? Voc√™ encontrou algum prompt interessante? Deixe seus coment√°rios abaixo!\n","date":"2 julho 2025","externalUrl":null,"permalink":"/pt-br/posts/20250702-gemini-cloud-assist/","section":"Posts","summary":"Como projetar infraestrutura usando linguagem natural usando o Gemini Cloud Assist no Google Cloud","title":"Do Prompt √† Infraestrutura com o Gemini Cloud Assist","type":"posts"},{"content":"","date":"2 julho 2025","externalUrl":null,"permalink":"/pt-br/tags/gemini/","section":"Tags","summary":"","title":"Gemini","type":"tags"},{"content":"","date":"2 julho 2025","externalUrl":null,"permalink":"/pt-br/tags/terraform/","section":"Tags","summary":"","title":"Terraform","type":"tags"},{"content":" Introdu√ß√£o # Neste guia, vamos aprender mais sobre system prompts e ferramentas de agente para que possamos construir uma nova e melhorada experi√™ncia de agente de diagn√≥stico. Trabalharemos com o Vertex AI SDK for Python, LangChain, Gemini e osquery.\nDevo admitir, a vers√£o inicial do agente de diagn√≥stico n√£o estava muito pronta para a \u0026ldquo;Enterprise\u0026rdquo; (trocadilho intencional). N√£o t√≠nhamos muita visibilidade sobre o que ele estava fazendo por baixo dos panos (ele estava realmente executando alguma query?), ele n√£o se lembrava de coisas discutidas na mesma \u0026ldquo;sess√£o\u0026rdquo; e, de vez em quando, tamb√©m ignorava nossos comandos completamente.\nIsso est√° longe da experi√™ncia que desejamos de um agente adequado. O agente de diagn√≥stico ideal precisa ser capaz de lembrar seus erros e executar instru√ß√µes de forma consistente, por exemplo, aprendendo que certas colunas n√£o est√£o dispon√≠veis e contornando isso. Al√©m disso, podemos realmente confiar que ele est√° fazendo o que diz que est√° fazendo? Devemos ser capazes de ver as queries a qualquer momento para garantir que as informa√ß√µes que ele est√° retornando est√£o corretas e atualizadas.\nCom esses objetivos em mente, vamos colocar as m√£os na massa e come√ßar a construir nosso Agente de Diagn√≥stico de Emerg√™ncia M√©dica Hologr√°fica!\nPreparando o Terreno # Da √∫ltima vez, escrevemos o c√≥digo em um Jupyter notebook por conveni√™ncia, mas desta vez vamos escrever um programa Python regular. O mesmo c√≥digo tamb√©m funcionaria no Jupyter com altera√ß√µes m√≠nimas, mas estamos fazendo isso para que possamos usar o agente de diagn√≥stico com uma interface de chat adequada.\nPara qualquer projeto Python, sempre recomendo come√ßar com um virtual env limpo para manter as depend√™ncias autocontidas:\n$ mkdir -p ~/projects/diagnostic-agent $ cd ~/projects/diagnostic-agent $ python3 -m venv venv $ source venv/bin/activate $ pip install --upgrade google-cloud-aiplatform[agent_engines,langchain] Aqui est√° a vers√£o inicial de main.py que reproduz o agente do artigo anterior:\nimport vertexai from vertexai import agent_engines import osquery from rich.console import Console from rich.markdown import Markdown import os PROJECT_ID = os.environ.get(\u0026#34;GCP_PROJECT\u0026#34;) LOCATION = os.environ.get(\u0026#34;GCP_REGION\u0026#34;, \u0026#34;us-central1\u0026#34;) STAGING_BUCKET = os.environ.get(\u0026#34;STAGING_BUCKET_URI\u0026#34;) vertexai.init( project=PROJECT_ID, location=LOCATION, staging_bucket=STAGING_BUCKET ) MODEL = os.environ.get(\u0026#34;GEMINI_MODEL\u0026#34;, \u0026#34;gemini-2.0-flash\u0026#34;) instance = osquery.SpawnInstance() def call_osquery(query: str): \u0026#34;\u0026#34;\u0026#34;Query the operating system using osquery This function is used to send a query to the osquery process to return information about the current machine, operating system and running processes. You can also use this function to query the underlying SQLite database to discover more information about the osquery instance by using system tables like sqlite_master, sqlite_temp_master and virtual tables. Args: query: str A SQL query to one of osquery tables (e.g. \u0026#34;select timestamp from time\u0026#34;) Returns: ExtensionResponse: an osquery response with the status of the request and a response to the query if successful. \u0026#34;\u0026#34;\u0026#34; if not instance.is_running(): instance.open() # This may raise an exception result = instance.client.query(query) return result def get_system_prompt(): if not instance.is_running(): instance.open() # This may raise an exception response = instance.client.query(\u0026#34;select name from sqlite_temp_master\u0026#34;).response tables = [ t[\u0026#34;name\u0026#34;] for t in response ] return f\u0026#34;\u0026#34;\u0026#34; Role: - You are the emergency diagnostic agent. - You are the last resort for the user to diagnose their computer problems. - Answer the user queries to the best of your capabilities. Tools: - you can call osquery using the call_osquery function. Context: - Only use tables from this list: {tables} - You can discover schemas using: PRAGMA table_info(table) Task: - Create a plan for which tables to query to fullfill the user request - Confirm the plan with the user before executing - If a query fails due a wrong column name, run schema discovery and try again - Query the required table(s) - Report the findings in a human readable way (table or list format) \u0026#34;\u0026#34;\u0026#34; def main(): agent = agent_engines.LangchainAgent( model = MODEL, system_instruction=get_system_prompt(), tools=[ call_osquery, ], ) console = Console() print(\u0026#34;Welcome to the Emergency Diagnostic Agent\\n\u0026#34;) print(\u0026#34;What is the nature of your diagnostic emergency?\u0026#34;) while True: try: query = input(\u0026#34;\u0026gt;\u0026gt; \u0026#34;) except EOFError: query = \u0026#34;exit\u0026#34; if query == \u0026#34;exit\u0026#34; or query == \u0026#34;quit\u0026#34;: break if query.strip() == \u0026#34;\u0026#34;: continue response = agent.query(input=query) rendered_markdown = Markdown(response[\u0026#34;output\u0026#34;]) console.print(rendered_markdown) print(\u0026#34;Goodbye!\u0026#34;) if __name__ == \u0026#34;__main__\u0026#34;: main() Voc√™ pode executar o agente com python main.py:\n$ python main.py Welcome to the Emergency Diagnostic Agent What is the nature of your diagnostic emergency? \u0026gt;\u0026gt; Existem duas pequenas altera√ß√µes em compara√ß√£o com o c√≥digo original: primeiro, agora temos um loop principal que manter√° o agente em execu√ß√£o at√© que o usu√°rio digite \u0026ldquo;exit\u0026rdquo; ou \u0026ldquo;quit\u0026rdquo;. Isso criar√° nossa interface de chat.\nSegundo, ajustamos o system prompt para melhorar a consist√™ncia do agente. Agora o chamamos de \u0026ldquo;Emergency Diagnostic Agent\u0026rdquo; - este nome n√£o apenas funciona como um elegante [easter egg de Star Trek]https://en.wikipedia.org/wiki/The_Doctor_(Star_Trek:_Voyager), mas tamb√©m define um tom de urg√™ncia que, com base em pesquisas emergentes, pode incentiv√°-lo a cumprir nossos pedidos com mais dilig√™ncia. (Confira tamb√©m esta entrevista recente (original em ingl√™s))\nN√£o vamos amea√ßar nosso pobre Agente de Diagn√≥stico de Emerg√™ncia - e posso garantir que nenhum agente foi prejudicado na produ√ß√£o deste texto - mas, cham√°-lo de agente de \u0026ldquo;Emerg√™ncia\u0026rdquo; deve definir o tom para que ele tente cumprir nossos pedidos da melhor maneira poss√≠vel. Na vers√£o anterior do system prompt, tive casos em que o agente se recusou a fazer uma tarefa porque \u0026ldquo;achava\u0026rdquo; que n√£o era capaz de faz√™-la ou n√£o sabia quais tabelas consultar.\nClaro, cham√°-lo de agente de emerg√™ncia n√£o √© suficiente para garantir o comportamento desejado, ent√£o adicionamos mais algumas instru√ß√µes para guiar o comportamento do modelo, como veremos abaixo.\nInstru√ß√µes de Sistema # Instru√ß√µes de sistema, tamb√©m chamadas de system prompt, s√£o um conjunto de instru√ß√µes que guiam o comportamento do LLM durante toda a conversa. As instru√ß√µes de sistema s√£o especiais, pois t√™m prioridade mais alta sobre as intera√ß√µes regulares de chat. Uma maneira de imaginar isso √© como se as instru√ß√µes de sistema fossem sempre repetidas junto com o prompt que voc√™ est√° enviando para o modelo.\nN√£o h√° um consenso forte na literatura sobre como um system prompt deve ser, mas temos alguns padr√µes testados em batalha que est√£o surgindo do uso di√°rio. Por exemplo, um que √© praticamente um consenso √© dedicar o in√≠cio do system prompt para atribuir um papel ao agente, para que ele esteja ciente de seu prop√≥sito e possa produzir respostas mais coerentes.\nPara este agente em particular, optei por incluir as seguintes se√ß√µes em meu system prompt: papel, ferramentas, contexto e tarefa. Essa estrutura funcionou bem durante minha fase de testes, mas n√£o se apegue demais a ela: experimente com seus prompts e veja se consegue resultados melhores. A experimenta√ß√£o √© fundamental para alcan√ßar bons resultados com LLMs.\nAgora vamos dar uma olhada em cada se√ß√£o do prompt.\nSystem Prompt: Papel # Um papel nada mais √© do que a raz√£o da exist√™ncia do agente. Pode ser t√£o simples quanto \u0026ldquo;voc√™ √© um engenheiro de software\u0026rdquo; ou \u0026ldquo;voc√™ √© um agente de diagn√≥stico\u0026rdquo;, mas podem ser um pouco mais elaborados, incluindo uma descri√ß√£o detalhada, regras de comportamento, restri√ß√µes e outros.\nPara um modelo de linguagem grande treinado em todos os tipos de dados, o papel ajuda a definir o tom para o conhecimento de dom√≠nio que ele precisar√° acessar para responder √†s suas perguntas. Em outras palavras, ele d√° significado sem√¢ntico √†s suas perguntas\u0026hellip; Imagine a pergunta \u0026ldquo;o que s√£o cookies?\u0026rdquo;, por exemplo. Estamos falando de cookies comest√≠veis ou cookies de navegador? Se o papel do agente for indefinido, essa pergunta √© completamente amb√≠gua, mas assim que definimos o papel para algo t√©cnico (por exemplo, \u0026ldquo;voc√™ √© um engenheiro de software\u0026rdquo;), a ambiguidade desaparece.\nPara este agente, o papel √© descrito como:\nRole: - You are the emergency diagnostic agent. - You are the last resort for the user to diagnose their computer problems. - Answer the user queries to the best of your capabilities. Al√©m da defini√ß√£o direta (\u0026ldquo;voc√™ √© o agente de diagn√≥stico de emerg√™ncia\u0026rdquo;), adicionamos uma descri√ß√£o mais longa para definir o tom do comportamento do modelo e, esperan√ßosamente, influenci√°-lo a levar nossos pedidos \u0026ldquo;a s√©rio\u0026rdquo;, como mencionado antes, a itera√ß√£o anterior deste agente tinha a m√° tend√™ncia de recusar pedidos.\nSystem Prompt: Ferramentas # Ferramentas √© a se√ß√£o que explica ao agente suas capacidades de interagir com sistemas externos al√©m de seu modelo principal. As ferramentas podem ser de v√°rios tipos, mas a maneira mais comum de fornecer uma ferramenta ao agente √© por meio de chamadas de fun√ß√£o.\nOs agentes podem usar ferramentas para recuperar informa√ß√µes, executar tarefas e manipular dados. O Vertex AI SDK for Python tem suporte para fun√ß√µes fornecidas pelo usu√°rio e ferramentas integradas como Google Search e execu√ß√£o de c√≥digo. Voc√™ tamb√©m pode usar extens√µes mantidas pela comunidade por meio da interface Model Context Protocol (MCP).\nPara nosso agente, precisamos dizer a ele que ele pode chamar o osquery:\nTools: - you can call osquery using the call_osquery function. System Prompt: Contexto # Em seguida, temos o contexto, que informa ao agente sobre o ambiente em que opera. Eu uso esta se√ß√£o para destacar explicitamente e corrigir comportamentos indesejados que itera√ß√µes anteriores do agente eram propensas a fazer. Por exemplo, percebi bem cedo no desenvolvimento que o agente tentaria \u0026ldquo;adivinhar\u0026rdquo; quais tabelas estavam dispon√≠veis e enviaria queries √†s cegas, resultando em uma alta taxa de erro. Adicionar a lista de tabelas ao contexto ajudou a mitigar esse problema.\nSemelhante √© a tend√™ncia do agente de tentar adivinhar os nomes das colunas em uma tabela, em vez de tentar descobrir os nomes primeiro. Neste caso particular, resisti √† tenta√ß√£o de instruir o agente a sempre usar SELECT * porque esta √© uma m√° pr√°tica (recupera mais dados do que o necess√°rio), mas em vez disso eu o \u0026ldquo;ensinei\u0026rdquo; como descobrir um schema usando a instru√ß√£o PRAGMA.\nDesta forma, o agente ainda cometer√° erros ao adivinhar nomes de colunas, mas tem uma maneira de corrigir o curso sem interven√ß√£o humana.\nA se√ß√£o de contexto revisada do system prompt √© mostrada abaixo.\nContext: - Only use tables from this list: {tables} - You can discover schemas using: PRAGMA table_info(table) Note que tables √© uma vari√°vel que cont√©m todas as tabelas que descobrimos do osquery antes de iniciar o modelo.\nSystem Prompt: Tarefa # Finalmente, a tarefa. Esta se√ß√£o √© usada para descrever como o agente deve interpretar seus pedidos e execut√°-los. As pessoas geralmente usam esta se√ß√£o para definir as etapas necess√°rias para realizar a tarefa em quest√£o.\nNo nosso caso particular, estamos usando esta se√ß√£o para definir aproximadamente o plano, mas tamb√©m adicionar algumas diretivas condicionais:\nTask: - Create a plan for which tables to query to fullfill the user request - Confirm the plan with the user before executing - If a query fails due a wrong column name, run schema discovery and try again - Query the required table(s) - Report the findings in a human readable way (table or list format) A etapa \u0026ldquo;confirmar o plano com o usu√°rio antes de executar\u0026rdquo; √© interessante, pois nos mostra como o agente est√° pensando sobre o processo, mas pode ser um pouco irritante depois de interagir com o agente por um tempo. Sempre podemos pedir ao agente para nos dizer o plano com um prompt, ent√£o a inclus√£o desta etapa √© totalmente opcional.\nInicialmente pensei nesta etapa como uma forma de depurar o agente, mas na se√ß√£o seguinte vamos explorar uma maneira diferente de fazer isso.\nCom a combina√ß√£o dessas quatro se√ß√µes, temos o system prompt completo. Este prompt revisado produziu resultados mais consistentes durante meus testes em prepara√ß√£o para este artigo. Ele tamb√©m tem o benef√≠cio de ser \u0026ldquo;amig√°vel ao ser humano\u0026rdquo;, por isso √© mais f√°cil de adaptar quando novas regras s√£o introduzidas.\nAqui est√° a vis√£o completa deste system prompt:\nRole: - You are the emergency diagnostic agent. - You are the last resort for the user to diagnose their computer problems. - Answer the user queries to the best of your capabilities. Tools: - you can call osquery using the call_osquery function. Context: - Only use tables from this list: {tables} - You can discover schemas using: PRAGMA table_info(table) Task: - Create a plan for which tables to query to fullfill the user request - Confirm the plan with the user before executing - If a query fails due a wrong column name, run schema discovery and try again - Query the required table(s) - Report the findings in a human readable way (table or list format) Como nota lateral, acredito que ainda temos muitas oportunidades para melhor√°-lo e uma das minhas atuais √°reas de interesse √© como alcan√ßar um system prompt autoaperfei√ßo√°vel. Isso poderia potencialmente ser alcan√ßado pedindo, ao final de uma sess√£o, para o modelo resumir seus aprendizados em um novo system prompt para sua itera√ß√£o futura. O prompt poderia ser armazenado em um banco de dados e carregado na pr√≥xima sess√£o. Isso, √© claro, levanta preocupa√ß√µes sobre a degrada√ß√£o do system prompt ou, pior ainda, ataques usando inje√ß√£o de prompt, ent√£o n√£o √© t√£o trivial quanto parece. No entanto, √© um exerc√≠cio divertido e posso escrever sobre isso em um futuro pr√≥ximo.\nHabilitando o Modo de Depura√ß√£o # Outra preocupa√ß√£o sobre o design original √© a falta de observabilidade sobre o que o agente est√° fazendo por baixo dos panos. Existem duas abordagens diferentes que podemos aplicar aqui, uma um pouco mais dolorosa que a outra: 1) espiar os \u0026ldquo;pensamentos\u0026rdquo; do LLM e tentar encontrar as chamadas de ferramenta entre eles (muito doloroso), ou; 2) adicionar alguma funcionalidade de depura√ß√£o √† pr√≥pria fun√ß√£o para que ela produza as informa√ß√µes que queremos durante a execu√ß√£o (a solu√ß√£o mais f√°cil geralmente √© a correta).\nDevo admitir, passei uma quantidade doentia de tempo na op√ß√£o 1, antes de perceber que poderia fazer a op√ß√£o 2. Se voc√™ realmente quer seguir o caminho do racioc√≠nio do LLM, pode faz√™-lo por meio de uma configura√ß√£o chamada return_intermediate_steps. Devo dizer que isso √© muito interessante do ponto de vista do aprendizado, mas depois de passar algumas horas tentando descobrir o formato da sa√≠da (dica: n√£o √© exatamente json) decidi que analisar n√£o valia realmente a pena.\nEnt√£o, como funciona a estrat√©gia simples? Estamos adicionando uma flag de depura√ß√£o e uma ferramenta para ativar e desativar essa flag. Este truque surpreendentemente simples na verdade abre um mundo totalmente novo de potencial: estamos dando ao agente a oportunidade de modificar seu pr√≥prio comportamento!\nA implementa√ß√£o do modo de depura√ß√£o √© composta por uma vari√°vel global e uma fun√ß√£o para configur√°-la:\ndebug = False def set_debug_mode(debug_mode: bool): \u0026#34;\u0026#34;\u0026#34;Toggle debug mode. Call this function to enable or disable debug mode. Args: debug_mode (bool): True to enable debug mode, False to disable it. Returns: None \u0026#34;\u0026#34;\u0026#34; global debug debug = debug_mode Tamb√©m precisamos mencion√°-lo no system prompt:\n... Tools: - you can call osquery using the call_osquery function. - you can enable or disable the debug mode using the set_debug_mode function. Context: ... E adicionar a fun√ß√£o √† lista de ferramentas na instancia√ß√£o do agente:\nagent = agent_engines.LangchainAgent( model = model, system_instruction=get_system_prompt(), tools=[ call_osquery, set_debug_mode, ], ) Finalmente, precisamos adaptar call_osquery para usar a nova flag debug:\ndef call_osquery(query: str): \u0026#34;\u0026#34;\u0026#34;Query the operating system using osquery This function is used to send a query to the osquery process to return information about the current machine, operating system and running processes. You can also use this function to query the underlying SQLite database to discover more information about the osquery instance by using system tables like sqlite_master, sqlite_temp_master and virtual tables. Args: query: str A SQL query to one of osquery tables (e.g. \u0026#34;select timestamp from time\u0026#34;) Returns: ExtensionResponse: an osquery response with the status of the request and a response to the query if successful. \u0026#34;\u0026#34;\u0026#34; if not instance.is_running(): instance.open() if debug: print(\u0026#34;Executing query: \u0026#34;, query) result = instance.client.query(query) if debug: print(\u0026#34;Query result: \u0026#34;, { \u0026#34;status\u0026#34;: result.status.message if result.status else None, \u0026#34;response\u0026#34;: result.response if result.response else None }) return result Com todas essas altera√ß√µes implementadas, vamos dar uma olhada em como o agente chama o osquery usando a flag de depura√ß√£o rec√©m-implementada:\n$ python main.py Welcome to the Emergency Diagnostic Agent What is the nature of your diagnostic emergency? \u0026gt;\u0026gt; run a level 1 diagnostic procedure in debug mode Executing query: SELECT * FROM system_info Query result: {\u0026#39;status\u0026#39;: \u0026#39;OK\u0026#39;, \u0026#39;response\u0026#39;: [{...}]} Executing query: SELECT pid, name, user, cpu_percent FROM processes ORDER BY cpu_percent DESC LIMIT 10 Query result: {\u0026#39;status\u0026#39;: \u0026#39;no such column: user\u0026#39;, \u0026#39;response\u0026#39;: None} Executing query: SELECT pid, name, user, resident_size FROM processes ORDER BY resident_size DESC LIMIT 10 Query result: {\u0026#39;status\u0026#39;: \u0026#39;no such column: user\u0026#39;, \u0026#39;response\u0026#39;: None} Executing query: PRAGMA table_info(processes) Query result: {\u0026#39;status\u0026#39;: \u0026#39;OK\u0026#39;, \u0026#39;response\u0026#39;: [{\u0026#39;cid\u0026#39;: \u0026#39;0\u0026#39;, \u0026#39;dflt_value\u0026#39;: \u0026#39;\u0026#39;, \u0026#39;name\u0026#39;: \u0026#39;pid\u0026#39;, \u0026#39;notnull\u0026#39;: \u0026#39;1\u0026#39;, \u0026#39;pk\u0026#39;: \u0026#39;1\u0026#39;, \u0026#39;type\u0026#39;: \u0026#39;BIGINT\u0026#39;}, ...]} (...) System Information: ‚Ä¢ Hostname: petruzalek-mac.roam.internal ‚Ä¢ CPU Type: arm64e ‚Ä¢ Physical Memory: 51539607552 bytes Top 5 Processes by CPU Usage: PID Name CPU Usage ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 1127 mediaanalysisd 95627517 43062 mediaanalysisd-access 66441942 54099 Google Chrome 3005046 54115 Google Chrome Helper (GPU) 2092500 81270 Electron 1688335 Top 5 Processes by Memory Usage (Resident Size): PID Name Resident Size (Bytes) ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 43062 mediaanalysisd-access 3933536256 54099 Google Chrome 1313669120 59194 Code Helper (Plugin) 1109508096 59025 Code Helper (Renderer) 915456000 19681 Google Chrome Helper (Renderer) 736329728 \u0026gt;\u0026gt; Observe que o comando emitido foi \u0026ldquo;run a level 1 diagnostic procedure in debug mode\u0026rdquo;, o que demonstra uma capacidade interessante do agente: invoca√ß√£o de m√∫ltiplas ferramentas. Se julgar necess√°rio, ele √© capaz de invocar n√£o apenas a mesma ferramenta v√°rias vezes, mas tamb√©m ferramentas diferentes ao mesmo tempo. Portanto, n√£o foi necess√°rio habilitar o modo de depura√ß√£o antes de solicitar o relat√≥rio: o agente conseguiu fazer tudo de uma vez.\nObserve tamb√©m como o agente falhou inicialmente ao solicitar uma coluna de usu√°rio, mas depois usou a instru√ß√£o PRAGMA para descobrir o schema correto e tentar novamente a query com sucesso. Esta √© uma demonstra√ß√£o perfeita da capacidade do agente de se recuperar de erros devido ao nosso system prompt aprimorado.\nPreservando o Hist√≥rico do Chat # Nossa tarefa final hoje √© garantir que o agente se lembre do que estamos falando para que possamos fazer perguntas de esclarecimento e investigar mais o sistema seguindo uma linha de investiga√ß√£o coerente.\nNo artigo anterior exploramos como os LLMs s√£o stateless e que precisamos continuar \u0026ldquo;lembrando-os\u0026rdquo; do estado atual da conversa usando \u0026ldquo;turnos\u0026rdquo;. Felizmente com o LangChain n√£o precisamos fazer isso manualmente e podemos contar com um recurso chamado chat history.\nA beleza do chat history √© que qualquer coisa que implemente BaseChatMessageHistory pode ser usada aqui, o que nos permite usar todos os tipos de armazenamentos de dados, incluindo a cria√ß√£o dos nossos pr√≥prios. Por exemplo, na documenta√ß√£o oficial do Vertex AI, voc√™ pode encontrar exemplos de uso de Firebase, Bigtable e Spanner.\nN√£o precisamos de um banco de dados completo no momento, ent√£o vamos nos contentar com InMemoryChatMessageHistory, que, como o nome sugere, armazenar√° tudo na mem√≥ria.\nAqui est√° uma implementa√ß√£o t√≠pica, tecnicamente suportando m√∫ltiplas sess√µes usando o dicion√°rio chats_by_session_id para pesquisa (c√≥digo retirado da documenta√ß√£o do langchain):\nchats_by_session_id = {} def get_chat_history(session_id: str) -\u0026gt; InMemoryChatMessageHistory: chat_history = chats_by_session_id.get(session_id) if chat_history is None: chat_history = InMemoryChatMessageHistory() chats_by_session_id[session_id] = chat_history return chat_history E aqui est√° nossa nova fun√ß√£o main instanciando o agente com o hist√≥rico de chat habilitado:\nimport uuid def main(): session_id = uuid.uuid4() agent = agent_engines.LangchainAgent( model = model, system_instruction=get_system_prompt(), tools=[ call_osquery, set_debug_mode, ], chat_history=get_chat_history, ) Um aviso r√°pido para que voc√™ n√£o cometa o mesmo erro que eu: o argumento chat_history espera um tipo Callable, ent√£o voc√™ n√£o deve invocar a fun√ß√£o ali, mas passar a pr√≥pria fun√ß√£o. O LangChain usa um padr√£o factory aqui; ele invoca a fun√ß√£o fornecida (get_chat_history) sob demanda com um session_id para obter ou criar o objeto de hist√≥rico correto. Este design √© o que permite ao agente gerenciar m√∫ltiplas conversas separadas simultaneamente.\nA assinatura da fun√ß√£o pode incluir um ou dois argumentos. Se um argumento, presume-se que seja um session_id, e se forem dois argumentos, eles s√£o interpretados como user_id e conversation_id. Mais informa√ß√µes sobre isso podem ser encontradas na documenta√ß√£o RunnableWithMessageHistory.\nA √∫ltima pe√ßa do quebra-cabe√ßa √© passar o session_id para o executor do modelo. Isso √© feito por meio do argumento config, conforme mostrado no c√≥digo abaixo:\n# (...) while True: try: query = input(\u0026#34;\u0026gt;\u0026gt; \u0026#34;) except EOFError: query = \u0026#34;exit\u0026#34; if query == \u0026#34;exit\u0026#34; or query == \u0026#34;quit\u0026#34;: break if query.strip() == \u0026#34;\u0026#34;: continue response = agent.query(input=query, config={\u0026#34;configurable\u0026#34;: {\u0026#34;session_id\u0026#34;: session_id}}) rendered_markdown = Markdown(response[\u0026#34;output\u0026#34;]) console.print(rendered_markdown) Agora, enquanto a sess√£o estiver ativa, podemos perguntar ao agente sobre informa√ß√µes em sua \u0026ldquo;mem√≥ria de curto prazo\u0026rdquo;, j√° que o conte√∫do da sess√£o √© armazenado na mem√≥ria. Isso ser√° suficiente para que a maioria das intera√ß√µes b√°sicas pare√ßam mais naturais, mas estamos abrindo precedentes para problemas maiores: agora que podemos armazenar informa√ß√µes da sess√£o, ap√≥s cada itera√ß√£o ela s√≥ crescer√° e, ao lidar com dados gerados automaticamente a partir de queries, o contexto da sess√£o crescer√° muito rapidamente, atingindo em breve os limites do modelo, e muito antes de atingirmos os limites da mem√≥ria do nosso computador.\nModelos como o Gemini s√£o bem conhecidos por suas longas janelas de contexto, mas mesmo um milh√£o de tokens podem ser esgotados muito rapidamente se preenchermos o contexto com dados. O contexto longo tamb√©m pode representar um problema para alguns modelos, pois a recupera√ß√£o se torna cada vez mais dif√≠cil - tamb√©m conhecido como o problema da agulha no palheiro.\nExistem t√©cnicas para lidar com o problema do contexto crescente, incluindo compress√£o e sumariza√ß√£o, mas, para manter o contexto deste artigo curto (viu o que eu fiz ali?), vamos guard√°-las para o pr√≥ximo artigo.\nA vers√£o final de main.py, incluindo todas as modifica√ß√µes neste artigo, fica assim:\nimport vertexai from vertexai import agent_engines import osquery from rich.console import Console from rich.markdown import Markdown from langchain_core.chat_history import InMemoryChatMessageHistory import os import uuid PROJECT_ID = os.environ.get(\u0026#34;GCP_PROJECT\u0026#34;) LOCATION = os.environ.get(\u0026#34;GCP_REGION\u0026#34;, \u0026#34;us-central1\u0026#34;) STAGING_BUCKET = os.environ.get(\u0026#34;STAGING_BUCKET_URI\u0026#34;) vertexai.init( project=PROJECT_ID, location=LOCATION, staging_bucket=STAGING_BUCKET ) MODEL = os.environ.get(\u0026#34;GEMINI_MODEL\u0026#34;, \u0026#34;gemini-2.5-pro-preview-05-06\u0026#34;) instance = osquery.SpawnInstance() debug = False def set_debug_mode(debug_mode: bool): \u0026#34;\u0026#34;\u0026#34;Toggle debug mode. Call this function to enable or disable debug mode. Args: debug_mode (bool): True to enable debug mode, False to disable it. Returns: None \u0026#34;\u0026#34;\u0026#34; global debug debug = debug_mode def call_osquery(query: str): \u0026#34;\u0026#34;\u0026#34;Query the operating system using osquery This function is used to send a query to the osquery process to return information about the current machine, operating system and running processes. You can also use this function to query the underlying SQLite database to discover more information about the osquery instance by using system tables like sqlite_master, sqlite_temp_master and virtual tables. Args: query: str A SQL query to one of osquery tables (e.g. \u0026#34;select timestamp from time\u0026#34;) Returns: ExtensionResponse: an osquery response with the status of the request and a response to the query if successful. \u0026#34;\u0026#34;\u0026#34; if not instance.is_running(): instance.open() # This may raise an exception if debug: print(\u0026#34;Executing query: \u0026#34;, query) result = instance.client.query(query) if debug: print(\u0026#34;Query result: \u0026#34;, { \u0026#34;status\u0026#34;: result.status.message if result.status else None, \u0026#34;response\u0026#34;: result.response if result.response else None }) return result def get_system_prompt(): if not instance.is_running(): instance.open() # This may raise an exception response = instance.client.query(\u0026#34;select name from sqlite_temp_master\u0026#34;).response tables = [ t[\u0026#34;name\u0026#34;] for t in response ] return f\u0026#34;\u0026#34;\u0026#34; Role: - You are the emergency diagnostic agent. - You are the last resort for the user to diagnose their computer problems. - Answer the user queries to the best of your capabilities. Tools: - you can call osquery using the call_osquery function. - you can use the set_debug_mode function to enable or disable debug mode. Context: - Only use tables from this list: {tables} - You can discover schemas using: PRAGMA table_info(table) Task: - Create a plan for which tables to query to fullfill the user request - Confirm the plan with the user before executing - If a query fails due a wrong column name, run schema discovery and try again - Query the required table(s) - Report the findings in a human readable way (table or list format) \u0026#34;\u0026#34;\u0026#34; chats_by_session_id = {} def get_chat_history(session_id: str) -\u0026gt; InMemoryChatMessageHistory: chat_history = chats_by_session_id.get(session_id) if chat_history is None: chat_history = InMemoryChatMessageHistory() chats_by_session_id[session_id] = chat_history return chat_history def main(): session_id = uuid.uuid4() agent = agent_engines.LangchainAgent( model = MODEL, system_instruction=get_system_prompt(), tools=[ call_osquery, set_debug_mode ], chat_history=get_chat_history, ) console = Console() print(\u0026#34;Welcome to the Emergency Diagnostic Agent\\n\u0026#34;) print(\u0026#34;What is the nature of your diagnostic emergency?\u0026#34;) while True: try: query = input(\u0026#34;\u0026gt;\u0026gt; \u0026#34;) except EOFError: query = \u0026#34;exit\u0026#34; if query == \u0026#34;exit\u0026#34; or query == \u0026#34;quit\u0026#34;: break if query.strip() == \u0026#34;\u0026#34;: continue response = agent.query(input=query, config={\u0026#34;configurable\u0026#34;: {\u0026#34;session_id\u0026#34;: session_id}}) rendered_markdown = Markdown(response[\u0026#34;output\u0026#34;]) console.print(rendered_markdown) print(\u0026#34;Goodbye!\u0026#34;) if __name__ == \u0026#34;__main__\u0026#34;: main() Conclus√µes # Neste artigo, aprendemos a import√¢ncia de ajustar um system prompt para obter respostas consistentes de um agente. Tamb√©m vimos na pr√°tica como funciona a chamada de m√∫ltiplas ferramentas e como usar ferramentas para habilitar ou desabilitar flags de recursos para alterar o comportamento do agente. Por √∫ltimo, mas n√£o menos importante, aprendemos sobre como gerenciar o estado da sess√£o usando o hist√≥rico de chat na mem√≥ria.\nNo pr√≥ximo artigo da s√©rie, veremos como habilitar a persist√™ncia entre sess√µes usando um banco de dados real, revisitaremos a no√ß√£o de tokens e discutiremos a t√©cnica de compress√£o de contexto.\nAp√™ndice: Coisas Divertidas para Tentar # Agora que nosso agente est√° mais robusto, use esta se√ß√£o como um guia pr√°tico para testar os novos recursos em a√ß√£o. Observe como ele agora se lembra do contexto entre as perguntas e como voc√™ pode pedir para ele explicar seu trabalho.\n\u0026gt;\u0026gt; run a level 1 diagnostic procedure \u0026gt;\u0026gt; run a level 2 diagnostic procedure \u0026gt;\u0026gt; explain the previous procedure step by step \u0026gt;\u0026gt; find any orphan processes \u0026gt;\u0026gt; show me the top resource consuming processes \u0026gt;\u0026gt; write a system prompt to transfer your current knowledge to another agent \u0026gt;\u0026gt; search the system for malware \u0026gt;\u0026gt; is this computer connected to the internet? \u0026gt;\u0026gt; why is my computer slow? \u0026gt;\u0026gt; take a snapshot of the current performance metrics \u0026gt;\u0026gt; compare the current perfomance metrics with the previous snapshot \u0026gt;\u0026gt; give me a step by step process to fix the issues you found \u0026gt;\u0026gt; how many osqueryd processes are in memory? \u0026gt;\u0026gt; give me a script to kill all osqueryd processes \u0026gt;\u0026gt; who am i? Se voc√™ encontrar outros prompts interessantes, por favor, compartilhe suas experi√™ncias na se√ß√£o de coment√°rios abaixo. At√© a pr√≥xima!\n","date":"11 junho 2025","externalUrl":null,"permalink":"/pt-br/posts/20250611-system-prompt/","section":"Posts","summary":"Este artigo explora os conceitos de instru√ß√£o de sistema, hist√≥rico de sess√£o e ferramentas de agente para criar um assistente de diagn√≥stico mais inteligente.","title":"Prompt Audacioso: Um Guia Pr√°tico para Instru√ß√µes de Sistema e Ferramentas de Agente","type":"posts"},{"content":"","date":"11 junho 2025","externalUrl":null,"permalink":"/pt-br/tags/python/","section":"Tags","summary":"","title":"Python","type":"tags"},{"content":"Daniela Petruzalek √© uma profissional de TI experiente com forma√ß√£o em engenharia de software, pr√©-vendas e rela√ß√µes com desenvolvedores, atualmente Engenheira S√™nior de Rela√ß√µes com Desenvolvedores no Google. Sua especializa√ß√£o √© engenharia de dados e desenvolvimento back-end e ela √© ex-Google Developer Expert em Go e Google Cloud Platform. Ela tamb√©m √© Google Cloud Certified Data Engineer, Oracle Certified Professional e palestrante TEDx. Em seu tempo livre, ela contribui para projetos de c√≥digo aberto, joga videogames e acaricia gatos aleat√≥rios nas ruas.\nPalestrando em Eventos Se voc√™ gostaria de me convidar para palestrar em seu evento, por favor, envie uma mensagem para daniela@danicat.dev com detalhes sobre o evento, incluindo p√∫blico, local e data.\nVoc√™ pode ver meu conte√∫do anterior no GitHub.\nM√≠dias Sociais Atualmente estou mais ativa no LinkedIn, mas sinta-se √† vontade para me seguir no X e BlueSky tamb√©m.\n","date":"11 junho 2025","externalUrl":null,"permalink":"/pt-br/about/","section":"danicat.dev","summary":"","title":"Sobre","type":"page"},{"content":"","date":"11 junho 2025","externalUrl":null,"permalink":"/pt-br/tags/vertex-ai/","section":"Tags","summary":"","title":"Vertex Ai","type":"tags"},{"content":" Introdu√ß√£o # Este artigo explora o modelo de comunica√ß√£o entre o c√≥digo do cliente e a API Gemini usando o SDK da Vertex AI para Python. Cobriremos conceitos como a estrutura das mensagens, como o modelo entende o contexto da pergunta e como aumentar as capacidades do modelo com chamadas de fun√ß√£o. Embora o Gemini seja o foco deste artigo, os mesmos conceitos que voc√™ ver√° aqui tamb√©m podem ser aplicados ao Gemma e outros LLMs.\nNo meu post anterior, expliquei como escrever um Agente de IA simples - mas surpreendentemente poderoso - que responde a perguntas de diagn√≥stico sobre sua m√°quina local. Em poucas linhas de c√≥digo (e n√£o t√£o poucas linhas de coment√°rios), conseguimos fazer nosso agente responder a consultas como ‚Äúquanta CPU eu tenho na minha m√°quina‚Äù ou ‚Äúpor favor, verifique se h√° sinais de malware‚Äù.\nIsso, claro, deveu-se √† beleza do SDK Python, pois simplificou muito as coisas. Por exemplo, contei com um recurso chamado Chamada de Fun√ß√£o Autom√°tica para permitir que o agente decidisse quando chamar uma fun√ß√£o. Esse recurso tamb√©m me ajudou a definir as fun√ß√µes como fun√ß√µes Python simples e o SDK descobriu sua assinatura e descri√ß√£o dinamicamente para mim. Essa capacidade, infelizmente, est√° dispon√≠vel apenas para o SDK Python, ent√£o os desenvolvedores em outras linguagens precisam trabalhar um pouco mais.\n√â por isso que no artigo de hoje vamos adotar uma abordagem um pouco diferente e discutir como a API Gemini funciona para que voc√™ possa estar mais bem preparado para usar n√£o apenas Python, mas qualquer um dos SDKs dispon√≠veis (JS, Go e Java). Continuarei usando Python para os exemplos para que voc√™ possa comparar com o artigo anterior, mas os conceitos discutidos aqui s√£o v√°lidos para todas as diferentes linguagens.\nVamos cobrir dois t√≥picos principais:\nComo funciona a conversa entre cliente e modelo Como implementar chamadas de fun√ß√£o manualmente Observe que, se voc√™ √© um desenvolvedor Python, isso tamb√©m n√£o significa que n√£o aprender√° nada com este artigo. Na verdade, entender o fluxo da conversa ser√° importante para usar conceitos mais avan√ßados do SDK (como a Live API) e trabalhar com LLMs em geral.\nEntendendo como a API funciona # Os agentes normalmente funcionam da mesma forma que os aplicativos cliente-servidor - voc√™ tem um componente cliente respons√°vel por preparar e fazer as solicita√ß√µes e um processo servidor que hospeda o tempo de execu√ß√£o do modelo e processa as solicita√ß√µes do cliente.\nPara a Vertex AI, existem dois grupos principais de APIs: uma API REST para o estilo t√≠pico de solicita√ß√£o/resposta de gera√ß√£o de conte√∫do, onde o cliente envia uma solicita√ß√£o e aguarda a resposta antes de continuar, e uma nova Live API que processa informa√ß√µes em tempo real usando websockets. Vamos nos concentrar primeiro nas APIs REST, pois a Live API requer um pouco mais de trabalho preparat√≥rio para funcionar corretamente.\nNormalmente, geramos conte√∫do em uma das seguintes modalidades: texto, imagem, √°udio e v√≠deo. Muitos dos modelos mais recentes tamb√©m s√£o multimodais, o que significa que voc√™ pode lidar com mais de uma modalidade de entrada e/ou sa√≠da ao mesmo tempo. Para simplificar, vamos come√ßar com texto.\nUm aplicativo t√≠pico de prompt √∫nico se parece com isto:\nfrom google import genai client = genai.Client( vertexai=True, project=\u0026#34;daniela-genai-sandbox\u0026#34;, location=\u0026#34;us-central1\u0026#34; ) response = client.models.generate_content( model=\u0026#34;gemini-2.0-flash\u0026#34;, contents=\u0026#34;How are you today?\u0026#34; ) print(response.text) Sa√≠da:\nEstou bem, obrigado por perguntar! Como um modelo de linguagem grande, n√£o experimento emo√ß√µes como os humanos, mas estou funcionando de forma otimizada e pronto para ajud√°-lo. Como posso ajud√°-lo hoje? A primeira coisa que precisamos fazer √© instanciar o cliente, usando o modo Vertex AI (vertexai=True) ou usando uma chave de API Gemini. Neste caso, estou usando o modo Vertex AI.\nAssim que o cliente √© inicializado, podemos enviar-lhe um prompt usando o m√©todo client.models.generate_content. Precisamos especificar qual modelo estamos chamando (neste caso gemini-2.0-flash) e o prompt no argumento contents (por exemplo, \u0026quot;How are you today?\u0026quot;).\nOlhando para este c√≥digo, pode ser dif√≠cil imaginar o que est√° acontecendo por baixo dos panos, pois estamos obtendo muitas abstra√ß√µes gratuitamente gra√ßas ao Python. A coisa mais importante neste caso √© que o conte√∫do n√£o √© uma string.\nContents √© na verdade uma lista de estruturas de conte√∫do, e as estruturas de conte√∫do s√£o compostas por uma fun√ß√£o (role) e uma ou mais partes (parts). O tipo subjacente para esta estrutura √© definido na biblioteca types e se parece com isto:\nfrom google.genai import types contents = [types.Content( role = \u0026#34;user\u0026#34;, parts = [ types.Part_from_text(\u0026#34;How are you today?\u0026#34;) )] Portanto, sempre que digitamos contents=\u0026quot;How are you today?\u0026quot;, o SDK Python faz essa transforma√ß√£o de string para ‚Äúconte√∫do com uma parte de string‚Äù automaticamente para n√≥s.\nOutra coisa importante a notar √© que sempre que fazemos uma chamada para generate_content, o modelo est√° come√ßando do zero. Isso significa que √© nossa responsabilidade adicionar o contexto das mensagens anteriores ao pr√≥ximo prompt. Vamos fazer um teste simples pedindo ao modelo que dia √© hoje duas vezes seguidas:\nresponse = client.models.generate_content( model=\u0026#34;gemini-2.0-flash\u0026#34;, contents=\u0026#34;what day is today?\u0026#34; ) print(response.text) response = client.models.generate_content( model=\u0026#34;gemini-2.0-flash\u0026#34;, contents=\u0026#34;what day is today?\u0026#34; ) print(response.text) Sa√≠da:\n$ python3 main.py Hoje √© domingo, 5 de novembro de 2023. Hoje √© s√°bado, 2 de novembro de 2024. Existem dois problemas com a resposta acima: 1) ela alucinou, pois o modelo n√£o tem como saber a data, e 2) deu duas respostas diferentes para a mesma pergunta. Podemos corrigir o 1) baseando-nos em uma ferramenta como uma chamada de datetime ou Pesquisa Google, mas quero focar no 2) porque mostra claramente que o modelo n√£o se lembra do que acabou de dizer e demonstra o ponto acima de que √© nossa responsabilidade manter o modelo atualizado sobre a conversa.\nVamos fazer uma pequena modifica√ß√£o no c√≥digo:\nresponse = client.models.generate_content( model=\u0026#34;gemini-2.0-flash\u0026#34;, contents=\u0026#34;what day is today?\u0026#34; ) print(response.text) # cada elemento no array de conte√∫dos √© geralmente referido como um \u0026#34;turno\u0026#34; contents = [ { \u0026#34;role\u0026#34;: \u0026#34;user\u0026#34;, \u0026#34;parts\u0026#34;: [{ \u0026#34;text\u0026#34;: \u0026#34;what day is today?\u0026#34; }] }, { \u0026#34;role\u0026#34;: \u0026#34;model\u0026#34;, \u0026#34;parts\u0026#34;: [{ \u0026#34;text\u0026#34;: response.text }] }, { \u0026#34;role\u0026#34;: \u0026#34;user\u0026#34;, \u0026#34;parts\u0026#34;: [{ \u0026#34;text\u0026#34;: \u0026#34;what day is today?\u0026#34; }] }, ] response = client.models.generate_content( model=\u0026#34;gemini-2.0-flash\u0026#34;, contents=contents ) print(response.text) Sa√≠da:\n$ python3 main.py Hoje √© quarta-feira, 15 de novembro de 2023. Hoje √© quarta-feira, 15 de novembro de 2023. Observe que na segunda chamada ao modelo estamos incluindo todo o contexto no atributo contents. Observe tamb√©m que a role de cada parte muda de ‚Äúuser‚Äù para ‚Äúmodel‚Äù e depois para ‚Äúuser‚Äù novamente (‚Äúuser‚Äù e ‚Äúmodel‚Äù s√£o os √∫nicos valores poss√≠veis para role). √â assim que o modelo entende em que ponto da conversa est√°, tamb√©m conhecido como ‚Äúturno‚Äù. Se, por exemplo, omit√≠ssemos a √∫ltima parte que repete a pergunta, o modelo pensaria que est√° atualizado e n√£o produziria outra resposta, pois o √∫ltimo turno seria de ‚Äúmodel‚Äù e n√£o de ‚Äúuser‚Äù.\nA vari√°vel contents acima est√° escrita na forma de ‚Äúdicion√°rio‚Äù, mas o SDK tamb√©m fornece v√°rios m√©todos de conveni√™ncia como types.UserContent (define o campo role como ‚Äúuser‚Äù automaticamente) e types.Part.from_text (converte uma string simples em uma parte), entre outros.\nPara lidar com outros tipos de entradas e/ou sa√≠das, podemos usar outros tipos de partes, como chamadas de fun√ß√£o, dados bin√°rios, etc. Se um modelo for multimodal, voc√™ pode misturar partes de diferentes tipos de conte√∫do na mesma mensagem.\nOs dados bin√°rios podem ser tanto inline quanto buscados de um URI. Voc√™ pode diferenciar entre diferentes tipos de dados usando o campo mime_type. Por exemplo, uma parte de imagem pode ser recuperada assim:\nfrom google.genai import types contents = types.Part.from_uri( file_uri: \u0026#39;gs://generativeai-downloads/images/scones.jpg\u0026#39;, mime_type: \u0026#39;image/jpeg\u0026#39;, ) Ou inline:\ncontents = types.Part.from_bytes( data: my_cat_picture, # dados bin√°rios mime_type: \u0026#39;image/jpeg\u0026#39;, ) Em resumo, para cada turno da conversa, adicionaremos uma nova linha de conte√∫do tanto para a resposta anterior do modelo quanto para a nova pergunta do usu√°rio.\nA boa not√≠cia √© que a experi√™ncia de chatbot √© um caso de uso t√£o importante que o SDK da Vertex AI fornece uma implementa√ß√£o para esse fluxo pronta para uso. Usando o recurso chat, podemos reproduzir o comportamento acima em poucas linhas de c√≥digo:\nchat = client.chats.create(model=\u0026#39;gemini-2.0-flash\u0026#39;) response = chat.send_message(\u0026#39;what day is today?\u0026#39;) print(response.text) response = chat.send_message(\u0026#39;what day is today?\u0026#39;) print(response.text) Sa√≠da:\n$ python3 main.py Hoje √© s√°bado, 14 de outubro de 2023. Hoje √© s√°bado, 14 de outubro de 2023. Desta vez, o modelo lembrou a data porque a interface de chat est√° lidando com o hist√≥rico automaticamente para n√≥s.\nChamada de fun√ß√£o n√£o autom√°tica # Agora que vimos como a API funciona para construir mensagens do cliente e gerenciar o contexto, √© hora de explorar como ela lida com chamadas de fun√ß√£o. Em um n√≠vel b√°sico, precisaremos instruir o modelo de que ele tem uma fun√ß√£o √† sua disposi√ß√£o e, em seguida, processar suas solicita√ß√µes para chamar a fun√ß√£o e retornar os valores resultantes ao modelo. Isso √© importante porque as chamadas de fun√ß√£o permitem que os agentes interajam com sistemas externos e o mundo real, criando a√ß√µes como recuperar dados ou acionar processos espec√≠ficos, indo al√©m de apenas gerar texto.\nA declara√ß√£o da fun√ß√£o √© o que diz ao modelo o que ele pode fazer. Ela informa ao modelo o nome da fun√ß√£o, a descri√ß√£o e seus argumentos. Por exemplo, abaixo est√° uma declara√ß√£o de fun√ß√£o para a fun√ß√£o get_random_number:\nget_random_number_decl = { \u0026#34;name\u0026#34;: \u0026#34;get_random_number\u0026#34;, \u0026#34;description\u0026#34;: \u0026#34;Retorna um n√∫mero aleat√≥rio\u0026#34;, } √â essa declara√ß√£o que o modelo precisa saber para decidir quais fun√ß√µes chamar. A declara√ß√£o da fun√ß√£o tem tr√™s campos: nome, descri√ß√£o e par√¢metros - neste caso, a fun√ß√£o n√£o aceita par√¢metros, ent√£o este campo √© omitido. O modelo usa a descri√ß√£o da fun√ß√£o e a descri√ß√£o de seus argumentos para decidir quando e como chamar cada fun√ß√£o.\nNo artigo anterior, em vez de dar ao modelo uma declara√ß√£o de fun√ß√£o, fui pregui√ßoso e deixei o SDK descobrir isso para mim com base no docstring da minha fun√ß√£o. Desta vez, vamos fazer diferente e declarar explicitamente uma fun√ß√£o para entender melhor o fluxo subjacente.\nA fun√ß√£o, incluindo sua declara√ß√£o, se parece com isto:\ndef get_random_number(): return 4 # escolhido por um lan√ßamento de dado justo # garantido ser aleat√≥rio (https://xkcd.com/221/) # a declara√ß√£o informa ao modelo o que ele precisa saber sobre a fun√ß√£o get_random_number_decl = { \u0026#34;name\u0026#34;: \u0026#34;get_random_number\u0026#34;, \u0026#34;description\u0026#34;: \u0026#34;Retorna um n√∫mero aleat√≥rio\u0026#34;, } Voc√™ pode ver outros exemplos de declara√ß√µes de fun√ß√£o aqui.\nEm seguida, precisamos dizer ao modelo que ele tem acesso a esta fun√ß√£o. Fazemos isso por meio da configura√ß√£o do modelo, adicionando a fun√ß√£o como uma ferramenta.\ntools = types.Tool(function_declarations=[get_random_number_decl]) config = types.GenerateContentConfig(tools=[tools]) # meu prompt inicial contents = [types.Part.from_text(text=\u0026#34;what is my lucky number today?\u0026#34;)] response = client.models.generate_content( model=\u0026#34;gemini-2.0-flash\u0026#34;, contents=contents, config=config, # observe como estamos adicionando a configura√ß√£o √† chamada do modelo ) print(response.candidates[0].content.parts[0]) Se voc√™ executar o c√≥digo acima, obter√° algo assim:\n$ python3 main.py video_metadata=None thought=None inline_data=None file_data=None thought_signature=None code_execution_result=None executable_code=None function_call=FunctionCall(id=None, args={}, name=\u0026#39;get_random_number\u0026#39;) function_response=None text=None O que voc√™ est√° vendo aqui √© a primeira parte da resposta do modelo, e podemos ver que esta parte tem todos os campos vazios (None), exceto o campo function_call. Isso significa que o modelo quer que n√≥s fa√ßamos essa chamada de fun√ß√£o e, em seguida, retornemos seu resultado de volta ao modelo.\nIsso inicialmente me intrigou, mas se voc√™ pensar bem, faz todo o sentido. O modelo sabe que a fun√ß√£o existe, mas n√£o tem absolutamente nenhuma ideia de como cham√°-la. Da perspectiva do modelo, a fun√ß√£o tamb√©m n√£o est√° rodando na mesma m√°quina, ent√£o o modelo n√£o pode fazer nada exceto ‚Äúpedir educadamente‚Äù para que fa√ßamos a chamada em seu nome.\nN√£o tivemos que fazer isso no meu artigo anterior porque a Chamada de Fun√ß√£o Autom√°tica assumiu o controle e simplificou as coisas para n√≥s. A chamada ainda seguiu o mesmo fluxo, mas o SDK escondeu toda essa complexidade de n√≥s.\nA coisa √≥bvia a fazer agora √© chamar a fun√ß√£o real e retornar o resultado para o modelo, mas lembre-se, sem contexto o modelo n√£o sabe nada sobre nossa solicita√ß√£o anterior, ent√£o se voc√™ enviar apenas os resultados da fun√ß√£o de volta, ele n√£o ter√° ideia do que fazer com isso!\n√â por isso que precisamos enviar o hist√≥rico da intera√ß√£o at√© agora, e pelo menos at√© o ponto em que o modelo sabe que solicitou esse valor. O c√≥digo abaixo assume que recebemos uma mensagem de chamada de fun√ß√£o e precisamos enviar uma nova solicita√ß√£o com as informa√ß√µes completas:\n# assumindo que j√° inspecionamos a resposta e sabemos o que o modelo quer result = get_random_number() # faz a chamada de fun√ß√£o real # contents ainda cont√©m o prompt original, ent√£o adicionaremos a resposta do modelo... contents.append(types.ModelContent(parts=response.candidates[0].content.parts)) # ... e o resultado da chamada de fun√ß√£o contents.append(types.UserContent(parts=types.Part.from_function_response(name=\u0026#34;get_random_number\u0026#34;, response={\u0026#34;result\u0026#34;: result}))) response = client.models.generate_content( model=\u0026#34;gemini-2.0-flash\u0026#34;, contents=contents, config=config, ) print(response.text) Sa√≠da:\n$ python3 main.py O n√∫mero da sorte de hoje √© 4. Conclus√µes # Neste artigo, vimos como o cliente do agente se comunica com o modelo no lado do servidor ou, em outras palavras, o ‚Äúmodelo de dom√≠nio‚Äù das comunica√ß√µes LLM. Tamb√©m removemos a cortina da ‚Äúm√°gica‚Äù que o SDK Python faz por n√≥s.\nA automa√ß√£o √© sempre conveniente e nos ajuda a alcan√ßar resultados muito mais rapidamente, mas saber como ela realmente funciona geralmente √© a grande diferen√ßa entre uma jornada tranquila e uma irregular ao implementar seu pr√≥prio agente, especialmente porque os casos especiais nunca s√£o t√£o f√°ceis.\nEu sei que em tempos de \u0026ldquo;vibe coding\u0026rdquo;, √† primeira vista, √© quase ir√¥nico dizer algo assim, mas uma das coisas que aprendi rapidamente ao programar no \u0026ldquo;vibe coding\u0026rdquo; √© que se voc√™ for mais preciso ao falar com a IA, obter√° resultados muito melhores em muito menos tempo. Portanto, agora n√£o √© hora de menosprezar o valor do conhecimento, mas sim de dobr√°-lo - n√£o apesar da IA, mas por causa dela.\nEspero que voc√™ tenha gostado da jornada at√© agora. No pr√≥ximo artigo, construiremos sobre este conhecimento para levar o agente de diagn√≥stico ao pr√≥ximo n√≠vel, onde nenhum agente jamais esteve! (ou talvez tenha estado, mas certamente n√£o o meu =^_^=)\nPor favor, escreva seus coment√°rios abaixo! Paz o/\n","date":"5 junho 2025","externalUrl":null,"permalink":"/pt-br/posts/20250605-vertex-ai-sdk-python/","section":"Posts","summary":"Este artigo explora o modelo de comunica√ß√£o entre o c√≥digo do cliente e a API Gemini usando o SDK da Vertex AI para Python","title":"Aprofundando-se no SDK da Vertex AI para Python","type":"posts"},{"content":"Espa√ßo: a fronteira final. Estas s√£o as viagens da nave estelar Enterprise. Sua miss√£o de 5 anos: explorar novos mundos estranhos; procurar novas vidas e novas civiliza√ß√µes; audaciosamente ir onde nenhum homem jamais esteve.\nIntrodu√ß√£o # Enquanto crescia, gra√ßas √† influ√™ncia do meu pai, acostumei-me a ouvir essas palavras quase todos os dias. Suspeito que a paix√£o dele por Star Trek desempenhou um papel enorme na minha escolha pela carreira de engenharia de software. (Para aqueles que n√£o est√£o familiarizados com Star Trek, este discurso era reproduzido no in√≠cio de cada epis√≥dio da s√©rie original de Star Trek)\nStar Trek sempre esteve √† frente de seu tempo. Mostrou o primeiro beijo inter-racial na televis√£o dos EUA, em tempos em que tal cena causava muita controv√©rsia. Tamb√©m retratou muitas pe√ßas de tecnologia ‚Äúfuturista‚Äù que hoje s√£o commodities, como smartphones e videoconfer√™ncia.\nUma coisa realmente not√°vel √© como os engenheiros da s√©rie interagem com os computadores. Embora vejamos alguns teclados e pressionamentos de bot√µes de vez em quando, muitos dos comandos s√£o vocalizados em linguagem natural. Alguns dos comandos que eles d√£o ao computador s√£o bastante ic√¥nicos, como por exemplo, quando solicitam ao computador para executar um ‚Äúprocedimento de diagn√≥stico de n√≠vel 1‚Äù, o que aconteceu tantas vezes que praticamente se tornou uma piada entre os f√£s mais ass√≠duos.\nAvan√ßando mais de 30 anos e aqui estamos n√≥s, na Era da IA, uma revolu√ß√£o tecnol√≥gica que promete ser maior que a internet. Claro que muitas pessoas est√£o com medo de como a IA pode impactar seus empregos (escrevi sobre isso na semana passada), mas crescer assistindo Star Trek torna mais f√°cil para mim ver como o papel do engenheiro mudar√° nos pr√≥ximos anos. Em vez de comandar o computador por meio de texto, instruindo manualmente cada etapa do caminho por meio de linhas de c√≥digo e compiladores, muito em breve passaremos a conversar e fazer brainstorming com nossos computadores.\nPara ajudar as pessoas a visualizar isso, vamos usar a tecnologia que temos hoje para criar um pequeno agente que nos permite interagir com nossas pr√≥prias m√°quinas usando linguagem natural.\nO que voc√™ precisar√° para esta demonstra√ß√£o # Para a linguagem de desenvolvimento, usaremos Python em um Jupyter Notebook, pois ele funciona muito bem para experimenta√ß√£o. As principais ferramentas e bibliotecas que usaremos s√£o:\nVertex AI Agent Engine Osquery com bindings para Python Jupyter Notebook [opcional] (na verdade, estou usando o plugin Jupyter para VSCode) Os exemplos abaixo usar√£o o Gemini Flash 2.0, mas voc√™ pode usar qualquer variante do modelo Gemini. N√£o implantaremos este agente no Google Cloud desta vez, pois queremos us√°-lo para responder a perguntas sobre a m√°quina local e n√£o sobre o servidor na nuvem.\nVis√£o Geral do Agente # Se voc√™ j√° est√° familiarizado com o funcionamento da tecnologia de agentes, pode pular esta se√ß√£o.\nUm agente de IA √© uma forma de IA capaz de perceber seu ambiente e tomar a√ß√µes aut√¥nomas para atingir objetivos espec√≠ficos. Se comparado com os t√≠picos Modelos de Linguagem Grande (LLMs), que se concentram principalmente na gera√ß√£o de conte√∫do com base na entrada, os agentes de IA podem interagir com seu ambiente, tomar decis√µes e executar tarefas para atingir seus objetivos. Isso √© alcan√ßado pelo uso de ‚Äúferramentas‚Äù que alimentar√£o o agente com informa√ß√µes e permitir√£o que ele realize a√ß√µes.\nPara demonstrar a tecnologia de agente, usaremos o LangChain por meio do Agent Engine. Primeiro, voc√™ precisa instalar os pacotes necess√°rios em seu sistema:\npip install --upgrade --quiet google-cloud-aiplatform[agent_engines,langchain] Voc√™ tamb√©m precisar√° definir suas credenciais padr√£o de aplicativo (ADC) do gcloud:\ngcloud auth application-default login Nota: dependendo do ambiente que voc√™ est√° usando para executar esta demonstra√ß√£o, pode ser necess√°rio usar um m√©todo de autentica√ß√£o diferente.\nAgora estamos prontos para trabalhar em nosso script Python. Primeiro, vamos inicializar o SDK com base no ID e local do nosso projeto do Google Cloud:\nimport vertexai vertexai.init( project=\u0026#34;my-project-id\u0026#34;, # Seu ID de projeto. location=\u0026#34;us-central1\u0026#34;, # Sua localiza√ß√£o na nuvem. staging_bucket=\u0026#34;gs://my-staging-bucket\u0026#34;, # Seu bucket de preparo. ) Uma vez feita a configura√ß√£o inicial, criar um agente usando LangChain no Agent Engine √© bastante simples:\nfrom vertexai import agent_engines model = \u0026#34;gemini-2.0-flash\u0026#34; # sinta-se √† vontade para experimentar diferentes modelos! model_kwargs = { # temperature (float): A temperatura de amostragem controla o grau de # aleatoriedade na sele√ß√£o de tokens. \u0026#34;temperature\u0026#34;: 0.20, } agent = agent_engines.LangchainAgent( model=model, # Obrigat√≥rio. model_kwargs=model_kwargs, # Opcional. ) A configura√ß√£o acima √© suficiente para voc√™ enviar consultas ao agente, assim como enviaria uma consulta a um LLM:\nresponse = agent.query( input=\u0026#34;which time is now?\u0026#34; ) print(response) O que poderia retornar algo assim:\n{\u0026#39;input\u0026#39;: \u0026#39;which time is now?\u0026#39;, \u0026#39;output\u0026#39;: \u0026#39;Como uma IA, eu n√£o tenho uma hora ou local \u0026#34;atuais\u0026#34; da mesma forma que um humano. Meu conhecimento n√£o √© atualizado em tempo real.\\n\\nPara saber a hora atual, voc√™ pode:\\n\\n* **Verificar seu dispositivo:** Seu computador, telefone ou tablet exibir√° a hora atual.\\n* **Fazer uma pesquisa r√°pida:** Digite \u0026#34;que horas s√£o\u0026#34; em um mecanismo de busca como o Google.\u0026#39;} Dependendo de suas configura√ß√µes, prompt e da aleatoriedade do universo, o modelo pode lhe dar uma resposta dizendo que n√£o pode lhe dizer a hora, ou pode ‚Äúalucinar‚Äù e inventar um timestamp. Mas, na verdade, como a IA n√£o tem rel√≥gio, ela n√£o ser√° capaz de responder a essa pergunta\u0026hellip; a menos que voc√™ lhe d√™ um rel√≥gio!\nChamadas de Fun√ß√£o # Uma das maneiras mais convenientes de estender as capacidades do nosso agente √© dar-lhe fun√ß√µes Python para chamar. O processo √© bastante simples, mas √© importante ressaltar que quanto melhor a documenta√ß√£o que voc√™ tiver para a fun√ß√£o, mais f√°cil ser√° para o agente acertar sua chamada. Vamos definir nossa fun√ß√£o para verificar a hora:\nimport datetime def get_current_time(): \u0026#34;\u0026#34;\u0026#34;Retorna a hora atual como um objeto datetime. Args: Nenhum Returns: datetime: hora atual como um tipo datetime \u0026#34;\u0026#34;\u0026#34; return datetime.datetime.now() Agora que temos uma fun√ß√£o que nos d√° a hora do sistema, vamos recriar o agente, mas agora ciente de que a fun√ß√£o existe:\nagent = agent_engines.LangchainAgent( model=model, # Obrigat√≥rio. model_kwargs=model_kwargs, # Opcional. tools=[get_current_time] ) E fa√ßa a pergunta novamente:\nresponse = agent.query( input=\u0026#34;which time is now?\u0026#34; ) print(response) A sa√≠da ser√° semelhante a esta:\n{\u0026#39;input\u0026#39;: \u0026#39;which time is now?\u0026#39;, \u0026#39;output\u0026#39;: \u0026#39;A hora atual √© 18:36:42 UTC de 30 de maio de 2025.\u0026#39;} Agora o agente pode contar com a ferramenta para responder √† pergunta com dados reais. Muito legal, hein?\nColetando Informa√ß√µes do Sistema # Para nosso agente de diagn√≥stico, vamos dar a ele recursos para consultar informa√ß√µes sobre a m√°quina em que est√° sendo executado usando uma ferramenta chamada osquery. Osquery √© uma ferramenta de c√≥digo aberto desenvolvida pelo Facebook para permitir que o usu√°rio fa√ßa consultas SQL a ‚Äútabelas virtuais‚Äù que exp√µem informa√ß√µes sobre o sistema operacional subjacente da m√°quina.\nIsso √© conveniente para n√≥s porque n√£o apenas nos d√° um √∫nico ponto de entrada para fazer consultas sobre o sistema, mas os LLMs tamb√©m s√£o muito proficientes em escrever consultas SQL.\nVoc√™ pode encontrar instru√ß√µes sobre como instalar o osquery na documenta√ß√£o oficial. N√£o vou reproduzi-las aqui porque elas variam dependendo do sistema operacional da sua m√°quina.\nDepois de instalar o osquery, voc√™ precisar√° instalar os bindings Python para o osquery. Como √© t√≠pico em Python, √© apenas um pip install:\npip install --upgrade --quiet osquery Com os bindings instalados, voc√™ pode fazer chamadas ao osquery importando o pacote osquery:\nimport osquery # Inicia um processo osquery usando um soquete de extens√£o ef√™mero. instance = osquery.SpawnInstance() instance.open() # Isso pode levantar uma exce√ß√£o # Emite consultas e chama APIs Thrift do osquery. instance.client.query(\u0026#34;select timestamp from time\u0026#34;) O m√©todo query retornar√° um objeto ExtensionResponse com os resultados de sua consulta. Por exemplo:\nExtensionResponse(status=ExtensionStatus(code=0, message=\u0026#39;OK\u0026#39;, uuid=0), response=[{\u0026#39;timestamp\u0026#39;: \u0026#39;Sex Mai 30 17:54:06 2025 UTC\u0026#39;}]) Se voc√™ nunca trabalhou com o osquery antes, encorajo voc√™ a dar uma olhada no schema para ver que tipo de informa√ß√£o est√° dispon√≠vel em seu sistema operacional.\nUma nota lateral sobre formata√ß√£o # Todas as sa√≠das dos exemplos anteriores n√£o foram formatadas, mas se voc√™ estiver executando o c√≥digo do Jupyter, poder√° acessar alguns m√©todos de conveni√™ncia para embelezar a sa√≠da importando os seguintes pacotes:\nfrom IPython.display import Markdown, display E exibindo a sa√≠da da resposta como markdown:\nresponse = agent.query( input=\u0026#34;what is today\u0026#39;s stardate?\u0026#34; ) display(Markdown(response[\u0026#34;output\u0026#34;])) Sa√≠da:\nDi√°rio do Capit√£o, Suplementar. A data estelar atual √© 48972.5. Conectando os pontos # Agora que temos uma maneira de consultar informa√ß√µes sobre o sistema operacional, vamos combinar isso com nosso conhecimento de agentes para criar um agente de diagn√≥stico que responder√° a perguntas sobre nosso sistema.\nO primeiro passo √© definir uma fun√ß√£o para fazer as consultas. Isso ser√° dado ao agente como uma ferramenta para coletar informa√ß√µes posteriormente:\ndef call_osquery(query: str): \u0026#34;\u0026#34;\u0026#34;Consulta o sistema operacional usando osquery Esta fun√ß√£o √© usada para enviar uma consulta ao processo osquery para retornar informa√ß√µes sobre a m√°quina atual, sistema operacional e processos em execu√ß√£o. Voc√™ tamb√©m pode usar esta fun√ß√£o para consultar o banco de dados SQLite subjacente para descobrir mais informa√ß√µes sobre a inst√¢ncia do osquery usando tabelas do sistema como sqlite_master, sqlite_temp_master e tabelas virtuais. Args: query: str Uma consulta SQL para uma das tabelas do osquery (por exemplo, \u0026#34;select timestamp from time\u0026#34;) Returns: ExtensionResponse: uma resposta do osquery com o status da solicita√ß√£o e uma resposta √† consulta, se bem-sucedida. \u0026#34;\u0026#34;\u0026#34; return instance.client.query(query) A fun√ß√£o em si √© bastante trivial, mas a parte importante aqui √© ter um docstring bem detalhado que permitir√° ao agente entender como essa fun√ß√£o funciona.\nDurante meus testes, um problema complicado que ocorreu com bastante frequ√™ncia foi que o agente n√£o sabia exatamente quais tabelas estavam dispon√≠veis em meu sistema. Por exemplo, estou executando uma m√°quina macOS e a tabela ‚Äúmemory_info‚Äù n√£o existe.\nPara dar ao agente um pouco mais de contexto, vamos fornecer dinamicamente os nomes das tabelas que est√£o dispon√≠veis neste sistema. Em uma situa√ß√£o ideal, voc√™ at√© daria a ele o schema inteiro com nomes de colunas e descri√ß√µes, mas infelizmente isso n√£o √© trivial de se conseguir com o osquery.\nA tecnologia de banco de dados subjacente para o osquery √© o SQLite, ent√£o podemos consultar a lista de tabelas virtuais da tabela sqlite_temp_master:\n# use um pouco de m√°gica Python para descobrir quais tabelas temos neste sistema response = instance.client.query(\u0026#34;select name from sqlite_temp_master\u0026#34;).response tables = [ t[\u0026#34;name\u0026#34;] for t in response ] Agora que temos todos os nomes das tabelas, podemos criar o agente com esta informa√ß√£o e a ferramenta call_osquery:\nosagent = agent_engines.LangchainAgent( model = model, system_instruction=f\u0026#34;\u0026#34;\u0026#34; Voc√™ √© um agente que responde a perguntas sobre a m√°quina em que est√° sendo executado. Voc√™ deve executar consultas SQL usando uma ou mais das tabelas para responder √†s perguntas do usu√°rio. Sempre retorne valores leg√≠veis por humanos (por exemplo, megabytes em vez de bytes e hora formatada em vez de milissegundos) Seja muito flex√≠vel em sua interpreta√ß√£o das solicita√ß√µes. Por exemplo, se o usu√°rio solicitar informa√ß√µes do aplicativo, √© aceit√°vel retornar informa√ß√µes sobre processos e servi√ßos. Se o usu√°rio solicitar o uso de recursos, retorne AMBAS as informa√ß√µes de mem√≥ria e CPU. N√£o pe√ßa esclarecimentos ao usu√°rio. Voc√™ tem as seguintes tabelas dispon√≠veis para voc√™: ----- TABELAS ----- {tables} ----- FIM TABELAS ----- Pergunta: \u0026#34;\u0026#34;\u0026#34;, tools=[ call_osquery, ] ) Acredite ou n√£o, nosso agente est√° pronto para todas as nossas perguntas! Vamos experimentar:\nresponse = osagent.query(input=\u0026#34;what is the current time?\u0026#34;) display(Markdown(response[\u0026#34;output\u0026#34;])) Sa√≠da:\nA hora atual √© Sex Mai 30 18:08:15 2025 UTC. Vamos complicar um pouco mais:\nresponse = osagent.query(input=\u0026#34;what is the top consuming process?\u0026#34;) display(Markdown(response[\u0026#34;output\u0026#34;])) Sa√≠da:\nO processo que mais consome CPU √©: Nome do Processo: mediaanalysisd, PID: 1127, Tempo Total de CPU: 2876716 O processo que mais consome mem√≥ria √©: Nome do Processo: Code Helper (Plugin), PID: 2987, Uso de Mem√≥ria: 1537 MB E se eu for um pouco mais criativo?\nresponse = osagent.query(input=\u0026#34;computer, run a level 1 diagnostic procedure\u0026#34;) display(Markdown(response[\u0026#34;output\u0026#34;])) Sa√≠da:\nAqui est√£o as informa√ß√µes de diagn√≥stico de n√≠vel 1: **Sistema Operacional:** * **Nome:** macOS * **Vers√£o:** 15.5 * **Build:** 24F74 * **Plataforma:** darwin * **Arquitetura:** arm64 ... omitido por quest√µes de brevidade ... **Tempo de Atividade:** * **Segundos Totais:** 261164 * **Dias:** 3 * **Horas:** 0 * **Minutos:** 32 * **Segundos:** 44 Uau! Eu nunca defini o que √© um procedimento de diagn√≥stico de N√≠vel 1, mas ele me deu um relat√≥rio bastante impressionante mesmo assim!\nAt√© tentei ser um pouco mais esperto nas minhas perguntas e as respostas n√£o decepcionaram (na maioria das vezes):\nresponse = osagent.query(input=\u0026#34;computer, do you see any signs of malware running?\u0026#34;) display(Markdown(response[\u0026#34;output\u0026#34;])) Sa√≠da:\nVerifiquei se h√° processos que n√£o est√£o associados a um arquivo em disco, o que pode ser um sinal de malware, e n√£o encontrei nenhum. Tamb√©m examinei os principais processos por uso de mem√≥ria e CPU. Os processos que consomem mais recursos s√£o principalmente o Visual Studio Code e o Google Chrome e seus processos auxiliares relacionados. Este √© um comportamento t√≠pico para esses aplicativos. Com base nas verifica√ß√µes realizadas, n√£o h√° sinais √≥bvios de malware em execu√ß√£o no sistema neste momento. Mic drop =^.^=\nConclus√µes # Eu sei que j√° √© um argumento batido, mas a IA √© um divisor de √°guas. Com pouqu√≠ssimas linhas de c√≥digo, passamos do zero para uma interface de linguagem natural totalmente funcional para o funcionamento interno do sistema operacional. Com um pouco mais de trabalho, este agente pode ser aprimorado para fazer diagn√≥sticos mais profundos e talvez at√© mesmo consertar coisas autonomamente. Scotty ficaria orgulhoso!\nVoc√™ pode encontrar o c√≥digo-fonte de todos os exemplos deste artigo no meu GitHub.\nQuais s√£o suas impress√µes? Compartilhe suas ideias nos coment√°rios abaixo.\n","date":"31 maio 2025","externalUrl":null,"permalink":"/pt-br/posts/20250531-diagnostic-agent/","section":"Posts","summary":"Como criar um agente de diagn√≥stico que fala linguagem natural usando Gemini e Vertex AI Agent Engine","title":"Como transformei meu computador na \"USS Enterprise\" usando Agentes de IA","type":"posts"},{"content":"","date":"28 maio 2025","externalUrl":null,"permalink":"/pt-br/tags/opiniao/","section":"Tags","summary":"","title":"Opiniao","type":"tags"},{"content":"","date":"28 maio 2025","externalUrl":null,"permalink":"/tags/opinion/","section":"Tags","summary":"","title":"Opinion","type":"tags"},{"content":" Introdu√ß√£o # Voc√™ acredita que um n√£o engenheiro pode programar um aplicativo pronto para produ√ß√£o no \u0026ldquo;vibe code\u0026rdquo;? Esta √© a pergunta sobre a qual tenho refletido ultimamente.\nO cen√°rio da IA est√° se movendo t√£o rapidamente, e estamos vendo tantas ferramentas legais sendo lan√ßadas quase todos os dias, ent√£o √© natural que muitas pessoas estejam ficando com medo e come√ßando a \u0026ldquo;prever\u0026rdquo; o fim da carreira de engenharia de software. Veja o Jules por exemplo, um agente de IA que pode automatizar muitas tarefas t√≠picas de engenheiros, como atualizar depend√™ncias, escrever documenta√ß√£o, refatorar e at√© mesmo testar.\nSe essas s√£o as √∫nicas coisas que voc√™ est√° agregando como engenheiro, talvez sim, voc√™ deva ter medo. Mas o medo n√£o √© necessariamente algo ruim, ele nos tira da zona de conforto, nos permite correr riscos que de outra forma n√£o correr√≠amos. Uma boa dose de medo impulsiona o autodesenvolvimento e a inova√ß√£o.\nAfinal, o que √© um Engenheiro? # Talvez eu n√£o seja a melhor pessoa para responder a essa pergunta porque, embora eu tenha estudado Engenharia El√©trica na faculdade, na verdade nunca me formei. No entanto, posso dizer que, mesmo sem diploma, o per√≠odo que passei no curso foi fundamental para moldar minha mentalidade ao abordar problemas em minha carreira.\nUm dos momentos cruciais que me influenciaram foi uma masterclass com o Dr. Ewaldo Mehl (UFPR) discutindo a carreira de engenharia para nossa turma de calouros. Entre muitas observa√ß√µes brilhantes, uma que ficou comigo at√© agora - mais de 20 anos depois - foi sobre a natureza do trabalho que fazemos\u0026hellip; Ele disse algo como: \u0026ldquo;Engenheiros s√£o os profissionais mais pr√≥ximos dos deuses (\u0026hellip;) porque n√£o apenas consertamos coisas, n√≥s as criamos.\u0026rdquo;\nSim, eu sei que este coment√°rio fora de contexto pode parecer estranho, mas o ponto principal da conversa estava relacionado ao \u0026ldquo;complexo de Deus\u0026rdquo; com o qual algumas carreiras como a Medicina frequentemente lutam, e meu professor estava tirando sarro disso dizendo que os engenheiros n√£o deveriam se sentir inferiores aos m√©dicos porque, na verdade, somos n√≥s que dever√≠amos ter esse complexo. (Por favor, mantenham os coment√°rios em ordem, isso foi no in√≠cio dos anos 2000, ent√£o est√°vamos muito pr√≥ximos dos anos 90 :-)\n√â um ditado comum de onde eu venho que no fundo de toda piada h√° um pouco de verdade, ent√£o, deixando as coisas de lado, acho que o Dr. Mehl estava certo em algo\u0026hellip; Removendo todas as ferramentas, em nossa ess√™ncia, somos criadores. A maneira como criamos evolui. Costumava ser com nossas pr√≥prias m√£os e mat√©rias-primas. Depois vieram ferramentas, computadores e rob√¥s. Agora, estamos entrando na era da IA.\nEnt√£o, sempre que voc√™ pensar sobre a carreira de engenharia - e se ela vai morrer ou n√£o - pense na necessidade humana de criar coisas novas. Sempre estaremos iterando, melhorando e inovando. Esta √© uma caracter√≠stica t√£o fundamental da natureza humana que n√£o consigo acreditar que v√° desaparecer, seja nos pr√≥ximos 5 anos ou no pr√≥ximo mil√™nio.\nMas a maneira como criamos e melhoramos as coisas, isso sim, acredito que vai mudar.\nOrquestrando, N√£o Apenas Codificando # Acho que a revolu√ß√£o da IA nos libertar√° das partes chatas para nos concentrarmos no aspecto mais empolgante do nosso trabalho: arquitetura, design, planejamento e teste das solu√ß√µes.\nN√£o estou dizendo que codificar em si √© chato. Na verdade, muito pelo contr√°rio, como a maioria dos engenheiros, gosto bastante de codificar. Mas manter c√≥digo profissional √© diferente de escrever c√≥digo por divers√£o. H√° tantas coisas que voc√™ escrever√° que n√£o se traduzem totalmente nas coisas que voc√™ deseja alcan√ßar.\nPense em todos os n√£o funcionais, como por exemplo seguran√ßa, logging, m√©tricas e networking; as horas gastas configurando, implantando, testando e validando; todas as etapas de configura√ß√£o para integrar diferentes camadas de aplica√ß√£o, bancos de dados e assim por diante\u0026hellip; Muitas das coisas que fazemos no dia a dia s√£o apenas para \u0026ldquo;fazer funcionar\u0026rdquo;, em oposi√ß√£o a realmente resolver um problema de neg√≥cio.\nMesmo tarefas simples, como configurar este blog, ainda me levaram alguns dias de trabalho - tive que configurar meu ambiente de desenvolvimento, pesquisar qual √© a melhor ferramenta para blogs em 2025, pesquisar op√ß√µes de hospedagem, pesquisar a linguagem de dom√≠nio usada para descrever blogs na minha plataforma escolhida (por exemplo, como os sites Hugo s√£o organizados), testar alguns templates antes de selecionar um, pesquisar como adicionar coment√°rios √†s postagens\u0026hellip; e assim por diante.\nComo tudo isso se relaciona com o problema de neg√≥cio que quero resolver? S√£o etapas importantes, mas s√≥ as fiz porque s√£o etapas necess√°rias para \u0026ldquo;fazer funcionar\u0026rdquo;, e n√£o realmente o que eu queria alcan√ßar em primeiro lugar.\nO que eu realmente quero √© criar uma fonte de verdade que eu possa usar para publicar posts de blog e depois transmiti-los para diferentes plataformas para melhor alcance (por exemplo, Medium, LinkedIn, etc.). Ainda n√£o consegui resolver este problema de neg√≥cio porque tive que me concentrar em todos os aspectos do pipeline de desenvolvimento de um novo aplicativo, desde o in√≠cio at√© a produ√ß√£o.\nQu√£o bom seria se pud√©ssemos abstrair tudo isso e apenas pedir a uma IA para \u0026ldquo;gerar uma plataforma de blog para mim, com tudo inclu√≠do\u0026rdquo;?\n√â aqui que a IA se tornar√° rapidamente muito poderosa. Com o nascimento da IA Ag√™ntica, em breve teremos milhares de agentes √† nossa disposi√ß√£o para orquestrar todas as etapas do processo de desenvolvimento de software, deixando-nos com a tarefa principal de idea√ß√£o de novas experi√™ncias, e a \u0026ldquo;operacionaliza√ß√£o\u0026rdquo; disso ser√° responsabilidade dos agentes. Eles ir√£o codificar, implantar e iterar. Eles far√£o a pesquisa por n√≥s e nos dar√£o op√ß√µes, para que possamos escolher de acordo com nossos ideais.\nPode ser dif√≠cil para voc√™ imaginar como isso funcionaria sem um exemplo concreto, mas √© por isso que amo fic√ß√£o cient√≠fica, pois nos permite dar uma espiada no futuro. Pense no computador de Star Trek\u0026hellip; Acredito que em alguns anos estaremos interagindo com o computador da mesma forma que Geordy La Forge faz nesta cena - o processo de engenharia se torna um di√°logo mais do que um esfor√ßo unilateral de um engenheiro.\nJ√° chegamos l√°? Na verdade n√£o, mas a IA Ag√™ntica √© o pr√≥ximo passo para tornar realidade o futuro retratado em Star Trek. Definitivamente, est√° come√ßando a parecer que a IA √© maior que a internet, e como desenvolvedores, devemos nos esfor√ßar para nos atualizarmos para a \u0026ldquo;pr√≥xima gera√ß√£o\u0026rdquo; (trocadilho intencional).\nEnt√£o, Qualquer Um Pode Programar no \u0026ldquo;Vibe Code\u0026rdquo;? # Talvez n√£o qualquer um, mas a barreira de entrada est√° definitivamente ficando mais baixa. As habilidades essenciais est√£o evoluindo, mas o papel do engenheiro de criar e arquitetar ainda est√° aqui e estar√° aqui por muito tempo.\nO que voc√™ acha? Voc√™ consegue se ver como um engenheiro mais \u0026ldquo;hands-off\u0026rdquo;, guiando a IA para dar vida √†s suas vis√µes? Vamos discutir nos coment√°rios!\n","date":"28 maio 2025","externalUrl":null,"permalink":"/pt-br/posts/20250528-vibe-coding/","section":"Posts","summary":"Uma reflex√£o sobre o futuro da carreira de engenharia de software.","title":"Qualquer um pode programar no \"vibe code\"?","type":"posts"},{"content":"Ol√° a todos, vamos falar sobre o Jules! Sa√≠do direto do forno do Google I/O, isto √© o que o Google chama de um agente de codifica√ß√£o aut√¥nomo‚Ä¶ mas o que √© um agente de codifica√ß√£o aut√¥nomo? Pense no NotebookLM, mas para codifica√ß√£o - uma IA especializada para ajud√°-lo com tarefas de programa√ß√£o. A principal diferen√ßa da abordagem tradicional de ‚Äúvibe coding‚Äù √© que com o Jules voc√™ pode importar todo o seu projeto como contexto para a IA, ent√£o todas as respostas s√£o baseadas no c√≥digo em que voc√™ est√° realmente trabalhando!\nDepois que o projeto √© importado, voc√™ pode interagir com o Jules enviando ‚Äútarefas‚Äù, que podem ser qualquer coisa, desde corre√ß√µes de bugs, atualiza√ß√µes de depend√™ncia, novos recursos, planejamento, documenta√ß√£o, testes e assim por diante. Assim que recebe uma tarefa, o Jules planejar√° assincronamente sua execu√ß√£o em etapas e realizar√° diferentes subtarefas para garantir que o resultado desejado seja alcan√ßado. Por exemplo, garantindo que nenhum teste foi quebrado pela nova altera√ß√£o.\nEle se integra diretamente com o GitHub, ent√£o h√° muito pouco atrito para come√ßar a us√°-lo. Ele ainda n√£o substituir√° completamente o IDE, mas voc√™ pode realizar muitas tarefas diretamente do Jules at√© o ponto em que ele cria um branch com todas as altera√ß√µes solicitadas, pronto para ser transformado em um pull request.\nA consequ√™ncia infeliz do an√∫ncio do Jules ontem √© que a ferramenta est√° atualmente sob forte carga, ent√£o pode levar um tempo depois que voc√™ envia uma tarefa para ver os resultados, mas o Jules far√° o trabalho em segundo plano e se voc√™ tiver as notifica√ß√µes do navegador ativadas, ele o avisar√° quando estiver pronto.\nDiante disso, n√£o consegui fazer grandes experimentos com ele, mas uma das coisas que fiz foi gerar o README para o projeto do meu blog no Github (a fonte desta mesma p√°gina que voc√™ est√° lendo agora). Tamb√©m tentei algumas itera√ß√µes mais complexas, como ajustar o template do blog. Ele gerou os arquivos corretos, mas demorou um pouco para responder √†s minhas solicita√ß√µes, ent√£o tive que fazer algumas altera√ß√µes manualmente.\nNada mal para o primeiro dia, eu diria, e h√° muito potencial a ser desbloqueado nas pr√≥ximas semanas e meses. O recurso matador √© a capacidade de trabalhar em uma base de c√≥digo completa, em vez daquele fluxo tradicional de fazer uma pergunta ao Gemini (ou ChatGPT), copiar o c√≥digo-fonte para o IDE, executar, copiar e colar de volta os resultados no LLM e iterar. Claro, ferramentas como Code Assist e CoPilot fornecer√£o algumas dessas capacidades sem sair do IDE, mas ainda sinto que o IDE n√£o √© o ambiente certo para o vibe coding, pois parece mais um hack.\nNesse esp√≠rito, talvez o Jules seja a inje√ß√£o de inspira√ß√£o que precis√°vamos para uma nova era de IDEs que desbloquear√° o potencial da IA para desenvolvedores em todo o mundo de uma forma mais natural. Pelo menos √© o que espero!\nO Jules est√° atualmente em beta p√∫blico e voc√™ pode brincar com ele hoje inscrevendo-se em https://jules.google.\n","date":"21 maio 2025","externalUrl":null,"permalink":"/pt-br/posts/20250521-jules/","section":"Posts","summary":"O novo agente de codifica√ß√£o aut√¥nomo que todo desenvolvedor precisa conhecer.","title":"Precisamos falar sobre o Jules!","type":"posts"},{"content":"Bem-vindo ao danicat.dev! Sou Daniela Petruzalek, engenheira de software com mais de 20 anos de experi√™ncia na √°rea e atualmente trabalho como Engenheira de Rela√ß√µes com Desenvolvedores no Google. Este √© o meu novo blog pessoal, onde vou compartilhar os √∫ltimos desenvolvimentos em tecnologia!\nSe voc√™ j√° est√° familiarizado com o meu conte√∫do da √©poca em que eu era Google Developer Expert, talvez saiba o que esperar, mas caso contr√°rio, confira meu conte√∫do anterior no meu reposit√≥rio do GitHub de apresenta√ß√µes p√∫blicas!\nEstou sempre aberta a colabora√ß√µes e palestras. Se voc√™ quiser me ver no seu pr√≥ximo evento, ou colaborar comigo em um v√≠deo ou podcast, por favor, entre em contato comigo no LinkedIn ou envie uma mensagem para daniela@danicat.dev\nPor enquanto √© s√≥, mas fique ligado para conte√∫do sobre engenharia de software, Google Cloud, GenAI, engenharia de dados e muito mais!\nDani =^.^=\nP.S.: Por favor, note que as opini√µes escritas neste blog s√£o minhas e n√£o representam as opini√µes do meu empregador! ^^\n","date":"20 maio 2025","externalUrl":null,"permalink":"/pt-br/posts/20250520-hello-world/","section":"Posts","summary":"Apenas algumas palavras para dar o pontap√© inicial neste blog!","title":"Ol√° Mundo","type":"posts"},{"content":"","externalUrl":null,"permalink":"/pt-br/authors/","section":"Authors","summary":"","title":"Authors","type":"authors"},{"content":"","externalUrl":null,"permalink":"/pt-br/series/","section":"Series","summary":"","title":"Series","type":"series"}]